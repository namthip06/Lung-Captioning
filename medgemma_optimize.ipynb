{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "314abfd3",
   "metadata": {},
   "source": [
    "### 1. ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞ Import Library\n",
    "\n",
    "- ‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á library ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô ‡πÄ‡∏ä‡πà‡∏ô unsloth, transformers, trl\n",
    "- transformers ‡∏Ñ‡∏∑‡∏≠ library ‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á HuggingFace ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏• NLP ‡πÅ‡∏•‡∏∞ Vision ‡∏ó‡∏µ‡πà pretrained ‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß\n",
    "- trl ‡πÄ‡∏≠‡∏≤‡πÑ‡∏ß‡πâ train/fine-tune ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ reinforcement learning ‡∏´‡∏£‡∏∑‡∏≠ supervised fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e41bd97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1) ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤ env\n",
    "# python -m venv .venv\n",
    "# # Windows: .\\.venv\\Scripts\\Activate.ps1\n",
    "# # Linux/macOS: source .venv/bin/activate\n",
    "# python -m pip install -U pip\n",
    "\n",
    "# # 2) ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏Å‡πà‡∏≤\n",
    "# pip uninstall -y torch torchvision torchaudio xformers\n",
    "\n",
    "# # 3) ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á PyTorch + CUDA runtime (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 1 ‡∏ó‡∏≤‡∏á)\n",
    "# pip install --index-url https://download.pytorch.org/whl/cu121 torch torchvision torchaudio\n",
    "# # ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ó‡∏µ‡πà‡∏´‡∏ô‡πâ‡∏≤ Get Started ‡πÉ‡∏´‡πâ‡∏°‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô CUDA ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì\n",
    "\n",
    "# # 4) xformers (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ô)\n",
    "# pip install xformers -f https://download.pytorch.org/whl/xformers/\n",
    "\n",
    "# # 5) Unsloth\n",
    "# pip install unsloth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6954f373",
   "metadata": {},
   "source": [
    "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ PyTorch ‡πÄ‡∏´‡πá‡∏ô GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c8fe0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.6\n",
      "Torch: 2.8.0+cu129\n",
      "Built with CUDA: 12.9\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch, platform\n",
    "\n",
    "print(\"Python:\", platform.python_version())\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"Built with CUDA:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f2fc6a",
   "metadata": {},
   "source": [
    "### 2. ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Vision-Language\n",
    "\n",
    "- ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Qwen2.5-VL (Vision-Language model) ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û + ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°\n",
    "- tokenizer ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (tokens)\n",
    "- load_in_4bit=True ‚Üí ‡πÉ‡∏ä‡πâ quantization 4-bit ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48ca3df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Lung-Captioning-main\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1015 10:47:18.828897 17584 Lib\\site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.9.11: Fast Gemma3 patching. Transformers: 4.56.2.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3060 Laptop GPU. Num GPUs = 1. Max memory: 6.0 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu129. CUDA: 8.6. CUDA Toolkit: 12.9. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: Gemma3 does not support SDPA - switching to fast eager.\n",
      "‚úÖ MedGemma-4B-IT Unsloth 4bit model loaded successfully!\n",
      "Model dtype: torch.bfloat16\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import unsloth\n",
    "import torch, platform\n",
    "from unsloth import FastVisionModel\n",
    "import torch\n",
    "import os\n",
    "os.environ[\"UNSLOTH_IS_PRESENT\"] = \"1\"\n",
    "\n",
    "# üß† Load MedGemma in 4-bit Unsloth mode\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/medgemma-4b-it-unsloth-bnb-4bit\",  # ‚úÖ your new model\n",
    "    load_in_4bit = True,                         # use 4-bit quantization (QLoRA ready)\n",
    "    use_gradient_checkpointing = \"unsloth\",      # save GPU memory while training\n",
    ")\n",
    "\n",
    "# üêâ Put the model into training or inference mode\n",
    "FastVisionModel.for_training(model)   # or .for_inference(model) later\n",
    "print(\"‚úÖ MedGemma-4B-IT Unsloth 4bit model loaded successfully!\")\n",
    "print(f\"Model dtype: {next(model.parameters()).dtype}\")\n",
    "print(f\"Device: {model.device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74992d2e",
   "metadata": {},
   "source": [
    "### 3. ‡πÄ‡∏û‡∏¥‡πà‡∏° LoRA (Low-Rank Adaptation)\n",
    "\n",
    "- ‡πÉ‡∏ä‡πâ LoRA (Low-Rank Adaptation) ‡πÄ‡∏û‡∏∑‡πà‡∏≠ fine-tune ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ö‡∏≤‡∏á‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞ train ‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "- ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏ù‡∏∂‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ vision part ‡∏´‡∏£‡∏∑‡∏≠ language part ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ccccafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.15.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Making `base_model.model.model.vision_tower.vision_model` require gradients\n"
     ]
    }
   ],
   "source": [
    "model = FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = True,    # ‚úÖ ‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏û‡∏¢‡∏≤‡∏ò‡∏¥‡∏™‡∏†‡∏≤‡∏û/feature ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á\n",
    "    finetune_language_layers   = False,   # ‚úÖ ‡∏£‡∏≠‡∏ö‡πÅ‡∏£‡∏Å‡∏Å‡∏±‡∏ô drift ‡∏†‡∏≤‡∏©‡∏≤ (‡∏¢‡∏±‡∏á generate ‡πÑ‡∏î‡πâ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ head/weights ‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ô infer)\n",
    "    finetune_attention_modules = True,    # ‚úÖ ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö cross-modal alignment (‡∏†‡∏≤‡∏û‚Üî‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°)\n",
    "    finetune_mlp_modules       = False,   # ‚úÖ ‡∏•‡∏î‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏° ‡∏Å‡∏±‡∏ô overfit / catastrophic forgetting\n",
    "\n",
    "    r = 16,                # ‚úÖ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏µ‡πà 16; ‡∏ñ‡πâ‡∏≤ underfit ‡∏Ñ‡πà‡∏≠‡∏¢‡∏Ç‡∏¢‡∏±‡∏ö 32 ‡∏û‡∏£‡πâ‡∏≠‡∏° rsLoRA\n",
    "    lora_alpha = 16,       # ‚úÖ ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö r ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ Unsloth\n",
    "    lora_dropout = 0.15,   # ‚úÖ ‡∏ä‡πà‡∏ß‡∏¢‡∏Å‡∏±‡∏ô overfit/‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏î‡∏¥‡∏° (‡πÄ‡∏ä‡πà‡∏ô‡∏ï‡∏≠‡∏ö \"Normal\" ‡∏£‡∏±‡∏ß ‡πÜ)\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    "\n",
    "    use_rslora = True,     # ‚úÖ ‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£‡∏Å‡∏±‡∏ö rank ‡∏™‡∏π‡∏á/‡∏á‡∏≤‡∏ô‡∏¢‡∏≤‡∏Å\n",
    "    loftq_config = None,   # ‚úÖ ‡∏ñ‡πâ‡∏≤‡πÄ‡∏ó‡∏£‡∏ô 4-bit ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏õ‡∏¥‡∏î LoftQ ‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå C ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û\n",
    "    # target_modules = [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"],  # ‚Üî ‡∏ñ‡πâ‡∏≤‡∏à‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞ attention ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏Ñ‡πà‡∏≠‡∏¢‡∏õ‡∏•‡∏î‡∏Ñ‡∏≠‡∏°‡πÄ‡∏°‡∏ô‡∏ï‡πå\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2811c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "hf = load_from_disk(\"lung8_image_text\")\n",
    "\n",
    "# ‡πÅ‡∏ö‡πà‡∏á train/test (30%) ‡∏Å‡πà‡∏≠‡∏ô\n",
    "splits = hf.train_test_split(test_size=0.3, seed=42, shuffle=True)\n",
    "train_hf = splits[\"train\"]\n",
    "tmp_hf   = splits[\"test\"]\n",
    "\n",
    "# ‡πÅ‡∏ö‡πà‡∏á tmp ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô val/test ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡∏Ñ‡∏£‡∏∂‡πà‡∏á ‚Üí ‡πÑ‡∏î‡πâ 15/15\n",
    "vt = tmp_hf.train_test_split(test_size=0.5, seed=42, shuffle=True)\n",
    "val_hf  = vt[\"train\"]\n",
    "test_hf = vt[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85025bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'text', '__class__'],\n",
       "    num_rows: 4259\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "246cdd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'text', '__class__'],\n",
       "    num_rows: 913\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f76c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from pathlib import Path\n",
    "\n",
    "# images_root = Path(path)\n",
    "# csv_dir     = Path(\"prepare_data/disease_output/csv\")\n",
    "\n",
    "# print(images_root)\n",
    "# print(csv_dir)\n",
    "# print(os.listdir(images_root))\n",
    "# print(os.listdir(csv_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da60a55",
   "metadata": {},
   "source": [
    "#### Main : dataset ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÄ‡∏≠‡∏á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e13b16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = (\n",
    "    \"You are an expert radiologist. \"\n",
    "    \"Describe the chest X-ray using precise clinical terms. \"\n",
    "    \"Identify one main diagnostic category from: \"\n",
    "    \"Chest_Changes, Degenerative_Infectious, Higher_Density, \"\n",
    "    \"Inflammatory_Pneumonia, Lower_Density, Mediastinal_Changes, Normal, or Obstructive.\"\n",
    ")\n",
    "\n",
    "def convert_to_conversation(sample):\n",
    "    cls_name = sample[\"__class__\"]\n",
    "    description = sample[\"text\"]\n",
    "\n",
    "    answer = f\"Class: {cls_name}\\nExplanation: {description}\"\n",
    "\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": \"You are a medical image interpretation assistant.\"}]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": instruction},\n",
    "                {\"type\": \"image\", \"image\": sample[\"image\"]}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": answer}]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return {\"messages\": conversation}\n",
    "\n",
    "# Convert your datasets\n",
    "train_ds      = [convert_to_conversation(sample) for sample in train_hf]\n",
    "val_ds        = [convert_to_conversation(sample) for sample in val_hf]\n",
    "test_ds       = [convert_to_conversation(sample) for sample in test_hf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "631f6654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'You are a medical image interpretation assistant.'}]},\n",
       "  {'role': 'user',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'You are an expert radiologist. Describe the chest X-ray using precise clinical terms. Identify one main diagnostic category from: Chest_Changes, Degenerative_Infectious, Higher_Density, Inflammatory_Pneumonia, Lower_Density, Mediastinal_Changes, Normal, or Obstructive.'},\n",
       "    {'type': 'image',\n",
       "     'image': <PIL.JpegImagePlugin.JpegImageFile image mode=L size=450x450>}]},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'Class: Lower_Density\\nExplanation: Collapsed lung / visceral pleural line observed showing visceral pleural line with absent peripheral lung markings on the left side. A small amount of apical collapse is noted. The remaining lung fields are clear. No associated pleural effusion is present. Findings are compatible with Lower density (pneumothorax, pneumomediastinum, pneumoperitoneum).'}]}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275b4461",
   "metadata": {},
   "source": [
    "#### Main: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17148a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import is_bf16_supported, FastVisionModel\n",
    "from unsloth.trainer import UnslothVisionDataCollator\n",
    "from transformers import EarlyStoppingCallback, TrainerCallback\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch, math, random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Any\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50c69596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 2) ‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏á‡∏≤‡∏ô (label set) ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏•‡πá‡∏Å ‡πÜ\n",
    "# ==========================\n",
    "CLASS_LABELS = [\n",
    "    \"Chest_Changes\", \"Degenerative_Infectious\", \"Higher_Density\",\n",
    "    \"Inflammatory_Pneumonia\", \"Lower_Density\", \"Mediastinal_Changes\",\n",
    "    \"Normal\", \"Obstructive\",\n",
    "]\n",
    "LABEL_SET = set(CLASS_LABELS)\n",
    "LABEL_TO_ID = {c:i for i,c in enumerate(CLASS_LABELS)}\n",
    "\n",
    "def extract_pred_class(text: str) -> str:\n",
    "    \"\"\"\n",
    "    ‡∏î‡∏∂‡∏á‡∏Ñ‡∏•‡∏≤‡∏™‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•:\n",
    "    ‡∏£‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏µ‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á/‡πÄ‡∏Ñ‡∏™/‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏™‡∏•‡∏±‡∏ö/‡∏°‡∏µ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
    "    \"\"\"\n",
    "    # ‡∏´‡∏≤ \"Class: <‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™>\"\n",
    "    m = re.search(r\"(?i)class\\s*:\\s*([A-Za-z0-9_\\- ]+)\", text)\n",
    "    if not m:\n",
    "        return None\n",
    "    raw = m.group(1).strip()\n",
    "    # ‡∏ó‡∏≥ normalization ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô\n",
    "    cand = raw.replace(\" \", \"_\")\n",
    "    # ‡πÄ‡∏ä‡πá‡∏Ñ map ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å (‡πÅ‡∏ö‡∏ö‡∏´‡∏¢‡∏ß‡∏ô‡πÜ)\n",
    "    # ‡∏•‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏ï‡∏±‡∏ß‡∏Å‡πà‡∏≠‡∏ô\n",
    "    if cand in LABEL_TO_ID: \n",
    "        return cand\n",
    "    # ‡∏•‡∏≠‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏ö‡∏ö lower-case\n",
    "    for c in CLASS_LABELS:\n",
    "        if cand.lower() == c.lower():\n",
    "            return c\n",
    "    # ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏∑‡∏ô None ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏à‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dc78969",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = \"\"\"\n",
    "Class: mEdiAsTinal cHanges\n",
    "Explanation: The chest X-ray shows increased transparency adjacent to both right and left cardiophrenic angles with variable clarity indicating partial atelectasis or pneumonia. This imaging feature suggests inflammatory change that is consistent with an underlying infectious etiology in this setting. The clinical scenario strongly supports infection leading to lung parenchymal changes. There are no visible effusions, mass lesions, or linear changes typical for entities like neoplasms or autoimmune conditions. The features are compatible with Degenerative_Infectious based on clinical and radiographic correlation, particularly considering the known clinical presentations associated with specific conditions in similar\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e84b374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mediastinal_Changes'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_pred_class(test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7904276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_l_f1(pred: str, ref: str) -> float:\n",
    "    \"\"\"\n",
    "    ROUGE-L F1 ‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢ (‡πÑ‡∏°‡πà‡∏û‡∏∂‡πà‡∏á external lib) ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á [0,1]\n",
    "    ‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô proxy ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û captioning ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ CIDEr\n",
    "    \"\"\"\n",
    "    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô token ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏≥‡πÅ‡∏ö‡∏ö‡∏´‡∏¢‡∏≤‡∏ö ‡πÜ\n",
    "    def tok(s): \n",
    "        return [w for w in s.strip().split() if w]\n",
    "    x, y = tok(pred.lower()), tok(ref.lower())\n",
    "    if not x or not y:\n",
    "        return 0.0\n",
    "    # LCS length (dynamic programming)\n",
    "    m, n = len(x), len(y)\n",
    "    dp = [[0]*(n+1) for _ in range(m+1)]\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if x[i] == y[j]:\n",
    "                dp[i+1][j+1] = dp[i][j] + 1\n",
    "            else:\n",
    "                dp[i+1][j+1] = max(dp[i][j+1], dp[i+1][j])\n",
    "    lcs = dp[m][n]\n",
    "    prec = lcs / max(1, m)\n",
    "    rec  = lcs / max(1, n)\n",
    "    if prec + rec == 0:\n",
    "        return 0.0\n",
    "    return 2 * prec * rec / (prec + rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23670e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_t = \"\"\"\n",
    "Class: Mediastinal_Changes\n",
    "Explanation: Findings are compatible with Arteriovenous malformations (pulmonary AVM may project as nodular opacity), characterized by well-circumscribed nodular opacity with suspected vascular connections may reflect pulmonary AVM (confirm on CT/angio). The nodular opacity warrants careful evaluation. Further imaging, such as a CT angiogram, is crucial for confirmation and characterization of feeding/draining vessels.\n",
    "\"\"\"\n",
    "\n",
    "ref_f = \"\"\"\n",
    "Class: Degenerative_Infectious\n",
    "Explanation: Reticulonodular pattern / interstitial fibrosis with coarse reticular opacities with volume loss, basilar and peripheral predominance (fibrotic pattern on CXR). Findings are compatible with Pulmonary fibrosis (e.g., IPF pattern on CXR). The reticular opacities are most evident in the lower lobes and periphery. There is associated volume loss and architectural distortion. These findings are highly suggestive of a fibrotic lung disease.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b6fd43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09333333333333334"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_l_f1(test_pred, ref_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b522aed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.125"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_l_f1(test_pred, ref_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7591f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1_from_predictions(y_true: List[int], y_pred: List[int]) -> float:\n",
    "    \"\"\"\n",
    "    macro-F1 ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏∂‡πà‡∏á sklearn (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° self-contained)\n",
    "    \"\"\"\n",
    "    num_classes = len(CLASS_LABELS)\n",
    "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á confusion ‡πÅ‡∏ö‡∏ö‡∏ô‡∏±‡∏ö TP/FP/FN ‡∏ï‡πà‡∏≠‡∏Ñ‡∏•‡∏≤‡∏™\n",
    "    tp = [0]*num_classes\n",
    "    fp = [0]*num_classes\n",
    "    fn = [0]*num_classes\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yp == yt:\n",
    "            tp[yt] += 1\n",
    "        else:\n",
    "            fp[yp] += 1\n",
    "            fn[yt] += 1\n",
    "    f1s = []\n",
    "    for c in range(num_classes):\n",
    "        p = tp[c] / max(1, (tp[c] + fp[c]))\n",
    "        r = tp[c] / max(1, (tp[c] + fn[c]))\n",
    "        if p + r == 0:\n",
    "            f1s.append(0.0)\n",
    "        else:\n",
    "            f1s.append(2*p*r/(p+r))\n",
    "    return float(np.mean(f1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cad4a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 3) Callback: ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô cls + cap ‡πÅ‡∏•‡πâ‡∏ß \"‡∏•‡πá‡∏≠‡∏Å\" metric (‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô KeyError)\n",
    "# ==========================\n",
    "class CaptionEvalCallback(TrainerCallback):\n",
    "    def __init__(self, eval_dataset, tokenizer, sample_size=256, max_new_tokens=96, seed=42):\n",
    "        self.eval_dataset = eval_dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.sample_size = sample_size\n",
    "        self.max_new_tokens = max_new_tokens\n",
    "        self.rng = random.Random(seed)\n",
    "\n",
    "    # --- ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏°‡πà‡∏°‡∏µ messages ‡πÉ‡∏ô row ---\n",
    "    def build_messages(self, image_obj) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        ‡∏Å‡∏£‡∏ì‡∏µ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏Å‡πà‡∏≤ (‡∏°‡∏µ 'image' ‡πÅ‡∏•‡∏∞ 'text') ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ 'messages'\n",
    "        ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° user ‡∏ï‡∏≤‡∏° prompt ‡πÄ‡∏î‡∏¥‡∏° + ‡πÅ‡∏ô‡∏ö‡∏†‡∏≤‡∏û\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\",\n",
    "                         \"text\": (\n",
    "                            \"Describe the chest X-ray using precise clinical terms. \"\n",
    "                            \"Identify one main diagnostic category from: \"\n",
    "                            \"Chest_Changes, Degenerative_Infectious, Higher_Density, \"\n",
    "                            \"Inflammatory_Pneumonia, Lower_Density, Mediastinal_Changes, \"\n",
    "                            \"Normal, or Obstructive.\"\n",
    "                         )},\n",
    "                        {\"type\": \"image\", \"image\": image_obj},\n",
    "                    ],\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def _extract_from_row(self, row: Dict[str, Any]):\n",
    "        \"\"\"\n",
    "        ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏∏‡∏Å‡∏Å‡∏£‡∏ì‡∏µ:\n",
    "        - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ 'messages': ‡πÉ‡∏ä‡πâ messages ‡πÄ‡∏î‡∏¥‡∏° (‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢, ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á chat template)\n",
    "            * ‡∏£‡∏π‡∏õ: ‡∏Ñ‡πâ‡∏ô‡πÉ‡∏ô user.content[type=='image']\n",
    "            * ref_caption: ‡πÉ‡∏ä‡πâ assistant.content[type=='text'] ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'text'\n",
    "        - ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ 'messages': ‡πÉ‡∏ä‡πâ row['image'] + row['text'] ‡πÅ‡∏•‡πâ‡∏ß‡∏™‡∏£‡πâ‡∏≤‡∏á messages ‡πÉ‡∏´‡∏°‡πà\n",
    "\n",
    "        ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤: messages(dict), ref_caption(str), true_cls(str)\n",
    "        \"\"\"\n",
    "        messages = None\n",
    "        ref_caption = row.get(\"text\", \"\") or \"\"       # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ 'text' ‡∏à‡∏∞‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏à‡∏≤‡∏Å assistant ‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á\n",
    "        true_cls = row.get(\"__class__\", \"\") or \"\"     # label ‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏•‡∏≤‡∏™\n",
    "\n",
    "        if \"messages\" in row and isinstance(row[\"messages\"], list):\n",
    "            # ‡πÉ‡∏ä‡πâ messages ‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á mismatch ‡∏Å‡∏±‡∏ö processor/data_collator\n",
    "            messages = {\"messages\": row[\"messages\"]}\n",
    "\n",
    "            # ‡∏´‡∏≤ image ‡∏à‡∏≤‡∏Å user turn ‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏°‡∏µ type=='image'\n",
    "            image_found = False\n",
    "            for turn in row[\"messages\"]:\n",
    "                if turn.get(\"role\") == \"user\":\n",
    "                    for c in (turn.get(\"content\") or []):\n",
    "                        if isinstance(c, dict) and c.get(\"type\") == \"image\" and c.get(\"image\") is not None:\n",
    "                            image_found = True\n",
    "                            break\n",
    "                if image_found:\n",
    "                    break\n",
    "\n",
    "            # ‡∏´‡∏≤ ref caption ‡∏à‡∏≤‡∏Å assistant ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ 'text'\n",
    "            if not ref_caption:\n",
    "                for turn in row[\"messages\"]:\n",
    "                    if turn.get(\"role\") == \"assistant\":\n",
    "                        for c in (turn.get(\"content\") or []):\n",
    "                            if isinstance(c, dict) and c.get(\"type\") == \"text\" and c.get(\"text\"):\n",
    "                                ref_caption = c[\"text\"]\n",
    "                                break\n",
    "                        if ref_caption:\n",
    "                            break\n",
    "\n",
    "            # ‡∏ñ‡πâ‡∏≤ messages ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏†‡∏≤‡∏û‡πÄ‡∏•‡∏¢ (rare) ‚Üí ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏° fallback ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏µ‡∏¢‡πå 'image'\n",
    "            if not image_found and row.get(\"image\", None) is not None:\n",
    "                messages = self.build_messages(row[\"image\"])\n",
    "\n",
    "        else:\n",
    "            # ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏Å‡πà‡∏≤: ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ 'image' ‡∏à‡∏∂‡∏á‡∏à‡∏∞ build ‡πÑ‡∏î‡πâ\n",
    "            img = row.get(\"image\", None)\n",
    "            if img is None:\n",
    "                # ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏†‡∏≤‡∏û‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‚Üí ‡πÇ‡∏¢‡∏ô error ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏ó‡∏ô KeyError\n",
    "                raise ValueError(\n",
    "                    \"No image found in row. Expected either 'messages' with an image content \"\n",
    "                    \"or an 'image' column.\"\n",
    "                )\n",
    "            messages = self.build_messages(img)\n",
    "\n",
    "        return messages, ref_caption, true_cls\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def on_evaluate(self, args, state, control, model=None, **kwargs):\n",
    "        model.eval()\n",
    "\n",
    "        # ----- ‡∏™‡∏∏‡πà‡∏° subset ‡∏à‡∏≤‡∏Å val_ds ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡πÄ‡∏ß‡∏•‡∏≤ evaluate -----\n",
    "        n = len(self.eval_dataset)\n",
    "        idxs = list(range(n))\n",
    "        self.rng.shuffle(idxs)\n",
    "        idxs = idxs[:min(self.sample_size, n)]\n",
    "\n",
    "        pred_classes, true_classes = [], []\n",
    "        rouge_ls = []\n",
    "\n",
    "        for i in idxs:\n",
    "            row = self.eval_dataset[i]\n",
    "\n",
    "            # ‚úÖ ‡∏î‡∏∂‡∏á messages/ref/label ‡πÅ‡∏ö‡∏ö‡∏Å‡∏±‡∏ô‡∏û‡∏±‡∏á ‡πÑ‡∏°‡πà‡∏ú‡∏π‡∏Å‡∏ï‡∏¥‡∏î‡∏Ñ‡∏µ‡∏¢‡πå 'image'\n",
    "            messages, ref_caption, true_cls = self._extract_from_row(row)\n",
    "\n",
    "            # ----- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏ï‡∏≤‡∏° template ‡∏Ç‡∏≠‡∏á‡∏£‡∏∏‡πà‡∏ô (‡πÉ‡∏ä‡πâ messages ‡∏ó‡∏µ‡πà‡∏™‡∏Å‡∏±‡∏î‡πÑ‡∏î‡πâ) -----\n",
    "            inputs = self.tokenizer.apply_chat_template(\n",
    "                messages[\"messages\"],\n",
    "                add_generation_prompt=True,\n",
    "                tokenize=True,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(model.device)\n",
    "\n",
    "            # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: Unsloth FastVisionModel ‡∏à‡∏∞ map ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å messages ‡∏ú‡πà‡∏≤‡∏ô data_collator/processor ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô\n",
    "            # ‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏£‡∏∏‡πà‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ kwargs ‡πÄ‡∏û‡∏¥‡πà‡∏° (‡πÄ‡∏ä‡πà‡∏ô pixel_values) ‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏±‡∏ö data_collator ‡πÉ‡∏´‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏°‡∏≤‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô\n",
    "\n",
    "            # ----- Generate -----\n",
    "            out = model.generate(\n",
    "                input_ids=inputs,\n",
    "                max_new_tokens=self.max_new_tokens,\n",
    "                do_sample=False\n",
    "            )\n",
    "            text = self.tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "            # ----- ‡πÅ‡∏¢‡∏Å \"‡∏Ñ‡∏•‡∏≤‡∏™\" ‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì ROUGE-L caption -----\n",
    "            pred_cls_str = extract_pred_class(text) or \"\"   # string ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå\n",
    "            if pred_cls_str in LABEL_SET:\n",
    "                pred_classes.append(LABEL_TO_ID[pred_cls_str])\n",
    "            else:\n",
    "                pred_classes.append(-1)  # ‡∏ñ‡πâ‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏≠‡∏≠‡∏Å‡πÉ‡∏´‡πâ mark -1 ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏£‡∏≠‡∏á‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á\n",
    "\n",
    "            true_classes.append(LABEL_TO_ID.get(true_cls, -1))\n",
    "\n",
    "            # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ ref_caption ‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà \"\" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ rouge_l_f1 ‡∏Ñ‡∏∑‡∏ô 0 ‡πÅ‡∏ó‡∏ô‡∏û‡∏±‡∏á\n",
    "            rouge_ls.append(rouge_l_f1(text, ref_caption or \"\"))\n",
    "\n",
    "        # ----- ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏µ -1 -----\n",
    "        y_true_clean, y_pred_clean = [], []\n",
    "        for yt, yp in zip(true_classes, pred_classes):\n",
    "            if yt >= 0 and yp >= 0:\n",
    "                y_true_clean.append(yt)\n",
    "                y_pred_clean.append(yp)\n",
    "\n",
    "        macro_f1 = macro_f1_from_predictions(y_true_clean, y_pred_clean) if y_true_clean else 0.0\n",
    "        rougeL   = float(np.mean(rouge_ls)) if rouge_ls else 0.0\n",
    "\n",
    "        # ----- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å metric ‡πÅ‡∏ö‡∏ö IN-PLACE ‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏µ‡∏¢‡πå‡∏õ‡∏Å‡∏ï‡∏¥‡πÅ‡∏•‡∏∞‡∏Ñ‡∏µ‡∏¢‡πå eval_ -----\n",
    "        metrics = kwargs.get(\"metrics\", None)\n",
    "        if metrics is not None:\n",
    "            # ‡∏Ñ‡∏µ‡∏¢‡πå‡∏õ‡∏Å‡∏ï‡∏¥ (‡∏î‡∏π‡∏Å‡∏£‡∏≤‡∏ü/log ‡πÑ‡∏î‡πâ‡∏™‡∏∞‡∏î‡∏ß‡∏Å)\n",
    "            metrics[\"macro_f1\"] = macro_f1\n",
    "            metrics[\"rougeL\"]   = rougeL\n",
    "            # ‡∏Ñ‡∏µ‡∏¢‡πå‡∏ó‡∏µ‡πà Trainer ‡∏à‡∏∞‡∏´‡∏≤‡πÅ‡∏ô‡πà ‡πÜ ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏¥‡∏° prefix 'eval_'\n",
    "            metrics[\"eval_macro_f1\"] = macro_f1\n",
    "            metrics[\"eval_rougeL\"]   = rougeL\n",
    "        # ‡∏´‡πâ‡∏≤‡∏° reassign ‡πÄ‡∏õ‡πá‡∏ô kwargs[\"metrics\"] = {...}  ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ in-place ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
    "\n",
    "        return control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "414d76eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 4) Callback: Gate ‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å captioning (‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥) + Early stopping ‡πÄ‡∏™‡∏£‡∏¥‡∏°\n",
    "#    - auto-resolve ‡∏Ñ‡∏µ‡∏¢‡πå metric ‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡πÅ‡∏ö‡∏ö‡∏°‡∏µ/‡πÑ‡∏°‡πà‡∏°‡∏µ prefix 'eval_'\n",
    "#    - ‡∏Å‡∏±‡∏ô NaN / missing metric\n",
    "# ==========================\n",
    "class SecondaryMetricGate(TrainerCallback):\n",
    "    def __init__(self, metric_key=\"rougeL\", min_value=0.35, patience=2):\n",
    "        \"\"\"\n",
    "        metric_key: ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å gate (‡πÄ‡∏ä‡πà‡∏ô \"rougeL\" ‡∏´‡∏£‡∏∑‡∏≠ \"eval_rougeL\")\n",
    "        min_value : ‡∏Ñ‡πà‡∏≤‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö (‡∏¢‡∏¥‡πà‡∏á‡∏°‡∏≤‡∏Å‡∏¢‡∏¥‡πà‡∏á‡∏î‡∏µ)\n",
    "        patience  : ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ô‡∏Å‡∏µ‡πà‡∏£‡∏≠‡∏ö‡∏à‡∏∂‡∏á‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏ó‡∏£‡∏ô\n",
    "        \"\"\"\n",
    "        self.metric_key = str(metric_key)\n",
    "        self.min_value = float(min_value)\n",
    "        self.patience = int(patience)\n",
    "        self.bad_epochs = 0\n",
    "        self._resolved_key = None  # ‡∏à‡∏∞ cache ‡∏Ñ‡∏µ‡∏¢‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏ä‡πà‡∏ô 'rougeL' ‡∏´‡∏£‡∏∑‡∏≠ 'eval_rougeL'\n",
    "\n",
    "    def _resolve_key(self, metrics: dict):\n",
    "        \"\"\"\n",
    "        ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏´‡∏≤ \"‡∏Ñ‡∏µ‡∏¢‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏à‡∏£‡∏¥‡∏á\" ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÅ‡∏•‡πâ‡∏ß cache ‡πÑ‡∏ß‡πâ:\n",
    "            - ‡∏ï‡∏£‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡πà‡∏á‡∏°‡∏≤ (metric_key)\n",
    "            - ‡πÄ‡∏ï‡∏¥‡∏°/‡∏ï‡∏±‡∏î prefix 'eval_'\n",
    "        \"\"\"\n",
    "        if self._resolved_key is not None:\n",
    "            return  # ‡πÄ‡∏Ñ‡∏¢ resolve ‡πÅ‡∏•‡πâ‡∏ß\n",
    "\n",
    "        candidates = [self.metric_key]\n",
    "        if self.metric_key.startswith(\"eval_\"):\n",
    "            candidates.append(self.metric_key[len(\"eval_\"):])           # ‡∏ï‡∏±‡∏î eval_\n",
    "        else:\n",
    "            candidates.append(f\"eval_{self.metric_key}\")                 # ‡πÄ‡∏ï‡∏¥‡∏° eval_\n",
    "\n",
    "        for k in candidates:\n",
    "            if k in metrics:\n",
    "                self._resolved_key = k\n",
    "                break\n",
    "        # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡∏Ñ‡∏á None ‡πÅ‡∏•‡πâ‡∏ß‡∏õ‡∏•‡πà‡∏≠‡∏¢‡∏ú‡πà‡∏≤‡∏ô‡∏£‡∏≠‡∏ö‡∏ô‡∏µ‡πâ (‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà gate)\n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        metrics = kwargs.get(\"metrics\", {}) or {}\n",
    "\n",
    "        # ‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏µ‡∏¢‡πå‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏≤‡∏Å metrics ‡∏Ç‡∏≠‡∏á‡∏£‡∏≠‡∏ö‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "        self._resolve_key(metrics)\n",
    "\n",
    "        if not self._resolved_key:\n",
    "            # ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏µ‡∏¢‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏£‡∏≠‡∏ö‡∏ô‡∏µ‡πâ ‚Üí ‡πÑ‡∏°‡πà gate\n",
    "            return control\n",
    "\n",
    "        val = metrics.get(self._resolved_key, None)\n",
    "        # ‡∏Å‡∏±‡∏ô NaN / None\n",
    "        try:\n",
    "            import math\n",
    "            if val is None or not math.isfinite(float(val)):\n",
    "                return control  # ‡πÑ‡∏°‡πà gate ‡∏ñ‡πâ‡∏≤‡∏Ñ‡πà‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ\n",
    "        except Exception:\n",
    "            return control\n",
    "\n",
    "        if float(val) < self.min_value:\n",
    "            # 1) ‡πÑ‡∏°‡πà save checkpoint ‡∏£‡∏≠‡∏ö‡∏ô‡∏µ‡πâ (‡∏Å‡∏±‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏ä‡πá‡∏Ñ‡∏û‡∏≠‡∏¢‡∏ï‡πå‡∏ó‡∏µ‡πà caption ‡πÅ‡∏¢‡πà‡∏°‡∏≤‡∏Å)\n",
    "            control.should_save = False\n",
    "            # 2) ‡∏ô‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à early stop\n",
    "            self.bad_epochs += 1\n",
    "            if self.bad_epochs >= self.patience:\n",
    "                control.should_training_stop = True\n",
    "        else:\n",
    "            self.bad_epochs = 0  # reset ‡∏ñ‡πâ‡∏≤‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå\n",
    "\n",
    "        return control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d3a714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 5) ‡πÄ‡∏£‡πà‡∏á‡∏Ñ‡∏ì‡∏¥‡∏ï‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ö‡∏ô GPU (TF32) + ‡πÄ‡∏õ‡∏¥‡∏î train\n",
    "# ==========================\n",
    "try:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "FastVisionModel.for_training(model)  # ‚úÖ enable training\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fe46b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 6) ‡∏™‡∏£‡πâ‡∏≤‡∏á Trainer + ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å \"‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\" ‡∏î‡πâ‡∏ß‡∏¢ macro_f1\n",
    "#    - eval/save ‡πÅ‡∏ö‡∏ö steps ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ callback ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ñ‡∏µ‡πà‡∏û‡∏≠\n",
    "#    - remove_unused_columns=False ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö VLM (‡∏£‡∏±‡∏Å‡∏©‡∏≤ fields image/messages)\n",
    "# ==========================\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = UnslothVisionDataCollator(model, tokenizer),\n",
    "    train_dataset = train_ds,\n",
    "    eval_dataset = val_ds,\n",
    "    args = SFTConfig(\n",
    "        # ===== core =====\n",
    "        output_dir=\"./outs\",\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=16,\n",
    "        learning_rate=1e-4,\n",
    "        num_train_epochs=2,\n",
    "        warmup_ratio=0.05,\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "\n",
    "        # ===== precision =====\n",
    "        bf16 = is_bf16_supported(),   # ‚úÖ ‡πÉ‡∏ä‡πâ‡∏ï‡∏≤‡∏°‡∏Æ‡∏≤‡∏£‡πå‡∏î‡πÅ‡∏ß‡∏£‡πå (Ampere+)\n",
    "        tf32 = True,\n",
    "\n",
    "        # ===== eval/save =====\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=300,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=300,\n",
    "        load_best_model_at_end=True,\n",
    "\n",
    "        # ‚úÖ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ï‡∏≤‡∏° \"macro_f1\" (‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å: classification)\n",
    "        # metric_for_best_model=\"macro_f1\",\n",
    "        # greater_is_better=True,\n",
    "\n",
    "        logging_steps=10,\n",
    "        save_total_limit=3,           # ‚úÖ ‡∏Å‡∏±‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏ä‡πá‡∏Ñ‡∏û‡∏≠‡∏¢‡∏ï‡πå‡πÄ‡∏¢‡∏≠‡∏∞\n",
    "\n",
    "        # ===== VLM safety =====\n",
    "        remove_unused_columns=False,  # ‚úÖ ‡∏≠‡∏¢‡πà‡∏≤‡∏ï‡∏±‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå messages/image\n",
    "        dataloader_num_workers=0,     # ‚úÖ ‡∏Å‡∏±‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤ pickle/vision worker\n",
    "        dataset_num_proc=1,           # ‚úÖ ‡∏Å‡∏±‡∏ô map ‡∏´‡∏•‡∏≤‡∏¢‡πÇ‡∏õ‡∏£‡πÄ‡∏ã‡∏™ (‡∏™‡πÄ‡∏ñ‡∏µ‡∏¢‡∏£)\n",
    "        per_device_eval_batch_size=2, # ‚úÖ ‡∏•‡∏î VRAM ‡∏Ç‡∏ì‡∏∞ eval+generate\n",
    "    ),\n",
    "    # ‡πÄ‡∏£‡∏≤ \"‡πÑ‡∏°‡πà\" ‡πÉ‡∏ä‡πâ compute_metrics ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏î‡∏±‡∏ö SFTTrainer ‡∏ï‡∏£‡∏á ‡πÜ\n",
    "    # ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ VLM+generate ‡∏°‡∏±‡∏Å‡∏ä‡∏ô‡∏Å‡∏±‡∏ö _pad_across_processes; ‡∏à‡∏∂‡∏á‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2b97ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 7) ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Callback:\n",
    "#    - EarlyStopping: ‡∏≠‡∏¥‡∏á metric_for_best_model (macro_f1)\n",
    "#    - CaptionEvalCallback: ‡πÄ‡∏ï‡∏¥‡∏° macro_f1 + rougeL ‡∏•‡∏á metrics ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà eval\n",
    "#    - SecondaryMetricGate: ‡∏Å‡∏±‡πâ‡∏ô checkpoint/‡∏´‡∏¢‡∏∏‡∏î ‡∏´‡∏≤‡∏Å caption ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏ì‡∏ë‡πå\n",
    "# ==========================\n",
    "trainer.add_callback(EarlyStoppingCallback(\n",
    "    early_stopping_patience=5,         # ‡∏ñ‡πâ‡∏≤ macro_f1 ‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô 5 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ï‡∏¥‡∏î ‚Üí ‡∏´‡∏¢‡∏∏‡∏î\n",
    "    early_stopping_threshold=1e-4\n",
    "))\n",
    "trainer.add_callback(CaptionEvalCallback(\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    sample_size=128,                   # ‚úÖ subset ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß (‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ)\n",
    "    max_new_tokens=96\n",
    "))\n",
    "trainer.add_callback(SecondaryMetricGate(\n",
    "    metric_key=\"rougeL\",               # ‚úÖ ‡πÉ‡∏ä‡πâ ROUGE-L ‡πÄ‡∏õ‡πá‡∏ô proxy ‡∏Ç‡∏≠‡∏á caption ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û\n",
    "    min_value=0.35,                    # ‚úÖ ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ (‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏ê‡∏≤‡∏ô)\n",
    "    patience=2\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fac08b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 3060 Laptop GPU. Max memory = 6.0 GB.\n",
      "3.92 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "# title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f45a70fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç∂ GPU memory = 6.44 GB\n",
      "‚úÖ Filled cup in: unsloth_zoo.gradient_checkpointing\n",
      "üîÅ Reloaded: unsloth_zoo.gradient_checkpointing\n",
      "üß† All kitchens now know target_gb = 6.44\n"
     ]
    }
   ],
   "source": [
    "import torch, sys, importlib\n",
    "\n",
    "gpu_mem_gb = round(torch.cuda.get_device_properties(0).total_memory / 1e9, 2)\n",
    "print(f\"üç∂ GPU memory = {gpu_mem_gb} GB\")\n",
    "\n",
    "# Patch every hidden kitchen (every loaded gradient_checkpointing)\n",
    "for name, module in list(sys.modules.items()):\n",
    "    if \"gradient_checkpointing\" in name:\n",
    "        try:\n",
    "            module.target_gb = gpu_mem_gb\n",
    "            print(\"‚úÖ Filled cup in:\", name)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "# Reload all gradient_checkpointing modules to ensure the new value sticks\n",
    "for name, module in list(sys.modules.items()):\n",
    "    if \"gradient_checkpointing\" in name:\n",
    "        importlib.reload(module)\n",
    "        print(\"üîÅ Reloaded:\", name)\n",
    "\n",
    "print(\"üß† All kitchens now know target_gb =\", gpu_mem_gb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df8a8e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "(1132462080, 6441926656)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.mem_get_info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1684e11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free GPU: 1.13 GB / 6.44 GB\n"
     ]
    }
   ],
   "source": [
    "import torch, os\n",
    "\n",
    "# Force CUDA context initialization\n",
    "torch.randn(1).to(\"cuda\")\n",
    "\n",
    "# Flush unused memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Check again\n",
    "free, total = torch.cuda.mem_get_info()\n",
    "print(f\"Free GPU: {free/1e9:.2f} GB / {total/1e9:.2f} GB\")\n",
    "\n",
    "# If still zero, override manually\n",
    "if free == 0:\n",
    "    os.environ[\"UNSLOTH_TARGET_GB\"] = \"6\"  # match your 6 GB GPU\n",
    "    print(\"‚ö†Ô∏è Forced UNSLOTH_TARGET_GB=6 because free memory read as 0.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84476c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 4,259 | Num Epochs = 2 | Total steps = 268\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 16\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 16 x 1) = 32\n",
      " \"-____-\"     Trainable parameters = 3,981,312 of 4,304,060,784 (0.09% trained)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjiraphat-sabutr\u001b[0m (\u001b[33mjiraphat-sabutr-king-mongkut-s-institute-of-technology-l\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Lung-Captioning-main\\wandb\\run-20251015_104850-t7lrn2h1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jiraphat-sabutr-king-mongkut-s-institute-of-technology-l/huggingface/runs/t7lrn2h1' target=\"_blank\">spring-sun-21</a></strong> to <a href='https://wandb.ai/jiraphat-sabutr-king-mongkut-s-institute-of-technology-l/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jiraphat-sabutr-king-mongkut-s-institute-of-technology-l/huggingface' target=\"_blank\">https://wandb.ai/jiraphat-sabutr-king-mongkut-s-institute-of-technology-l/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jiraphat-sabutr-king-mongkut-s-institute-of-technology-l/huggingface/runs/t7lrn2h1' target=\"_blank\">https://wandb.ai/jiraphat-sabutr-king-mongkut-s-institute-of-technology-l/huggingface/runs/t7lrn2h1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [huggingface_hub.inference] in use.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='268' max='268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [268/268 8:51:52, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth import unsloth_train\n",
    "\n",
    "trainer_stats = unsloth_train(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4b8bf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32369.1214 seconds used for training.\n",
      "539.49 minutes used for training.\n",
      "Peak reserved memory = 5.301 GB.\n",
      "Peak reserved memory for training = 1.381 GB.\n",
      "Peak reserved memory % of max memory = 88.35 %.\n",
      "Peak reserved memory for training % of max memory = 23.017 %.\n"
     ]
    }
   ],
   "source": [
    "# title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35a592b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final metrics: {'train_runtime': 32369.1214, 'train_samples_per_second': 0.263, 'train_steps_per_second': 0.008, 'total_flos': 8.095445099774573e+16, 'train_loss': 3.4778788481185687, 'epoch': 2.0}\n",
      "Latest eval_loss: N/A\n",
      "Final eval_loss (if present): None\n"
     ]
    }
   ],
   "source": [
    "# ‡∏û‡∏¥‡∏°‡∏û‡πå metric ‡∏™‡∏£‡∏∏‡∏õ‡∏£‡∏ß‡∏°‡∏ï‡∏≤‡∏°‡πÄ‡∏î‡∏¥‡∏°\n",
    "print(\"Final metrics:\", trainer_stats.metrics)\n",
    "\n",
    "# ‡∏î‡∏∂‡∏á eval_loss ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÄ‡∏ó‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏¢‡πâ‡∏≠‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å log_history\n",
    "def latest_eval_metric(trainer, key=\"eval_loss\"):\n",
    "    # log_history ‡πÄ‡∏Å‡πá‡∏ö dict ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≠‡∏ö: {'eval_loss': ..., 'step': ..., 'epoch': ...}\n",
    "    for log in reversed(trainer.state.log_history):\n",
    "        if key in log:\n",
    "            return {\n",
    "                \"value\": log[key],\n",
    "                \"step\": log.get(\"step\", log.get(\"global_step\", None)),\n",
    "                \"epoch\": log.get(\"epoch\", None),\n",
    "                \"raw\": log,  # ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏≠‡∏¢‡∏≤‡∏Å‡∏î‡∏π‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "            }\n",
    "    return None\n",
    "\n",
    "latest = latest_eval_metric(trainer, key=\"eval_loss\")\n",
    "\n",
    "if latest is not None:\n",
    "    print(f\"Latest eval_loss: {latest['value']} (step={latest['step']}, epoch={latest['epoch']})\")\n",
    "else:\n",
    "    # fallback: ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‡∏•‡∏≠‡∏á‡∏î‡∏π‡∏ó‡∏µ‡πà‡∏ú‡∏•‡∏£‡∏ß‡∏°‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢\n",
    "    print(\"Latest eval_loss: N/A\")\n",
    "    print(\"Final eval_loss (if present):\", trainer_stats.metrics.get(\"eval_loss\", None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb195c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 3.4778788481185687\n",
      "All metrics: {'train_runtime': 32369.1214, 'train_samples_per_second': 0.263, 'train_steps_per_second': 0.008, 'total_flos': 8.095445099774573e+16, 'train_loss': 3.4778788481185687, 'epoch': 2.0}\n",
      "Index(['loss', 'grad_norm', 'learning_rate', 'epoch', 'step', 'train_runtime',\n",
      "       'train_samples_per_second', 'train_steps_per_second', 'total_flos',\n",
      "       'train_loss'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>grad_norm</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.8893</td>\n",
       "      <td>1.486123</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.075117</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.8908</td>\n",
       "      <td>0.753054</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.150235</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.8387</td>\n",
       "      <td>0.371180</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.7954</td>\n",
       "      <td>0.637880</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.300469</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.7683</td>\n",
       "      <td>0.483315</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.375587</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.7020</td>\n",
       "      <td>0.576292</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.450704</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.6472</td>\n",
       "      <td>0.713668</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.525822</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.6445</td>\n",
       "      <td>0.761558</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.600939</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.6011</td>\n",
       "      <td>0.452591</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.5315</td>\n",
       "      <td>0.701271</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.751174</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.5281</td>\n",
       "      <td>0.502099</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.826291</td>\n",
       "      <td>110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.4944</td>\n",
       "      <td>0.959665</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.901408</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.4333</td>\n",
       "      <td>0.763307</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.976526</td>\n",
       "      <td>130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.3711</td>\n",
       "      <td>0.399439</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>1.045070</td>\n",
       "      <td>140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.3599</td>\n",
       "      <td>0.769499</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>1.120188</td>\n",
       "      <td>150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.3309</td>\n",
       "      <td>0.334652</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>1.195305</td>\n",
       "      <td>160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.3281</td>\n",
       "      <td>0.523739</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>1.270423</td>\n",
       "      <td>170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.3105</td>\n",
       "      <td>0.479803</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.345540</td>\n",
       "      <td>180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.2969</td>\n",
       "      <td>0.507052</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>1.420657</td>\n",
       "      <td>190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.2883</td>\n",
       "      <td>0.357975</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1.495775</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.2693</td>\n",
       "      <td>0.334439</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>1.570892</td>\n",
       "      <td>210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.2812</td>\n",
       "      <td>0.393358</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>1.646009</td>\n",
       "      <td>220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.2600</td>\n",
       "      <td>0.377132</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.721127</td>\n",
       "      <td>230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.2471</td>\n",
       "      <td>0.370601</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1.796244</td>\n",
       "      <td>240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.2359</td>\n",
       "      <td>0.333436</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.871362</td>\n",
       "      <td>250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.2414</td>\n",
       "      <td>0.350187</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.946479</td>\n",
       "      <td>260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>268</td>\n",
       "      <td>32369.1214</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.008</td>\n",
       "      <td>8.095445e+16</td>\n",
       "      <td>3.477879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      loss  grad_norm  learning_rate     epoch  step  train_runtime  \\\n",
       "0   3.8893   1.486123       0.000064  0.075117    10            NaN   \n",
       "1   3.8908   0.753054       0.000098  0.150235    20            NaN   \n",
       "2   3.8387   0.371180       0.000094  0.225352    30            NaN   \n",
       "3   3.7954   0.637880       0.000090  0.300469    40            NaN   \n",
       "4   3.7683   0.483315       0.000086  0.375587    50            NaN   \n",
       "5   3.7020   0.576292       0.000082  0.450704    60            NaN   \n",
       "6   3.6472   0.713668       0.000078  0.525822    70            NaN   \n",
       "7   3.6445   0.761558       0.000074  0.600939    80            NaN   \n",
       "8   3.6011   0.452591       0.000070  0.676056    90            NaN   \n",
       "9   3.5315   0.701271       0.000067  0.751174   100            NaN   \n",
       "10  3.5281   0.502099       0.000063  0.826291   110            NaN   \n",
       "11  3.4944   0.959665       0.000059  0.901408   120            NaN   \n",
       "12  3.4333   0.763307       0.000055  0.976526   130            NaN   \n",
       "13  3.3711   0.399439       0.000051  1.045070   140            NaN   \n",
       "14  3.3599   0.769499       0.000047  1.120188   150            NaN   \n",
       "15  3.3309   0.334652       0.000043  1.195305   160            NaN   \n",
       "16  3.3281   0.523739       0.000039  1.270423   170            NaN   \n",
       "17  3.3105   0.479803       0.000035  1.345540   180            NaN   \n",
       "18  3.2969   0.507052       0.000031  1.420657   190            NaN   \n",
       "19  3.2883   0.357975       0.000027  1.495775   200            NaN   \n",
       "20  3.2693   0.334439       0.000023  1.570892   210            NaN   \n",
       "21  3.2812   0.393358       0.000019  1.646009   220            NaN   \n",
       "22  3.2600   0.377132       0.000015  1.721127   230            NaN   \n",
       "23  3.2471   0.370601       0.000011  1.796244   240            NaN   \n",
       "24  3.2359   0.333436       0.000007  1.871362   250            NaN   \n",
       "25  3.2414   0.350187       0.000004  1.946479   260            NaN   \n",
       "26     NaN        NaN            NaN  2.000000   268     32369.1214   \n",
       "\n",
       "    train_samples_per_second  train_steps_per_second    total_flos  train_loss  \n",
       "0                        NaN                     NaN           NaN         NaN  \n",
       "1                        NaN                     NaN           NaN         NaN  \n",
       "2                        NaN                     NaN           NaN         NaN  \n",
       "3                        NaN                     NaN           NaN         NaN  \n",
       "4                        NaN                     NaN           NaN         NaN  \n",
       "5                        NaN                     NaN           NaN         NaN  \n",
       "6                        NaN                     NaN           NaN         NaN  \n",
       "7                        NaN                     NaN           NaN         NaN  \n",
       "8                        NaN                     NaN           NaN         NaN  \n",
       "9                        NaN                     NaN           NaN         NaN  \n",
       "10                       NaN                     NaN           NaN         NaN  \n",
       "11                       NaN                     NaN           NaN         NaN  \n",
       "12                       NaN                     NaN           NaN         NaN  \n",
       "13                       NaN                     NaN           NaN         NaN  \n",
       "14                       NaN                     NaN           NaN         NaN  \n",
       "15                       NaN                     NaN           NaN         NaN  \n",
       "16                       NaN                     NaN           NaN         NaN  \n",
       "17                       NaN                     NaN           NaN         NaN  \n",
       "18                       NaN                     NaN           NaN         NaN  \n",
       "19                       NaN                     NaN           NaN         NaN  \n",
       "20                       NaN                     NaN           NaN         NaN  \n",
       "21                       NaN                     NaN           NaN         NaN  \n",
       "22                       NaN                     NaN           NaN         NaN  \n",
       "23                       NaN                     NaN           NaN         NaN  \n",
       "24                       NaN                     NaN           NaN         NaN  \n",
       "25                       NaN                     NaN           NaN         NaN  \n",
       "26                     0.263                   0.008  8.095445e+16    3.477879  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ‡∏î‡∏π‡∏Ñ‡πà‡∏≤‡∏£‡∏ß‡∏°\n",
    "print(\"Training loss:\", trainer_stats.training_loss)\n",
    "print(\"All metrics:\", trainer_stats.metrics)\n",
    "\n",
    "# ‡πÅ‡∏õ‡∏•‡∏á log ‡πÄ‡∏õ‡πá‡∏ô DataFrame\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(trainer.state.log_history)\n",
    "\n",
    "# ‡∏î‡∏π‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ\n",
    "print(df.columns)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8341f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhgAAAGJCAYAAADIVkprAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAYKFJREFUeJzt3XlclNX+B/DPzADDOsMmsgoIuACCW9pkqaUo2iWXFtPMtNumdrP1V1YKaKbZbfHajSwtSyNNM81cEC3c9xV3URAXEAHZGRhmnt8fXkZHBhhg4GH5vF8vXjLPc+bhO98B+XLOec6RCIIggIiIiMiMpGIHQERERK0PCwwiIiIyOxYYREREZHYsMIiIiMjsWGAQERGR2bHAICIiIrNjgUFERERmxwKDiIiIzI4FBhEREZkdCwyiRjBx4kT4+fnV67kxMTGQSCTmDagVWbp0KSQSCdLS0kT5+g15b4naEhYY1KZIJBKTPpKSksQOVVTJycmQSCQ4cOBAtW0GDhxYbf66dOnShNGa3/Xr1xETE4Njx46JHYpeWloaJBIJ/v3vf4sdCpFJLMQOgKgpLVu2zODxTz/9hMTExCrHu3bt2qCv891330Gn09XruR9++CHee++9Bn39htqwYQPc3Nxw33331djO29sbc+fOrXJcqVQ2VmhN4vr164iNjYWfnx+6d+9ucK4h7y1RW8ICg9qU8ePHGzzet28fEhMTqxy/V0lJCWxtbU3+OpaWlvWKDwAsLCxgYSHuj+bGjRsxbNiwWodqlEplrblrbRry3hK1JRwiIbrHwIEDERoaisOHD6N///6wtbXF+++/DwBYt24dHn30UXh6ekIulyMgIACzZ8+GVqs1uMa94/R3d29/++23CAgIgFwux3333YeDBw8aPNfYHAyJRIJXX30Va9euRWhoKORyOUJCQrB58+Yq8SclJaF3796wtrZGQEAAFi1aVKd5HXl5edizZw8effRRk9rXZPXq1ZBIJNi+fXuVc4sWLYJEIsHJkycBACdOnMDEiRPRsWNHWFtbw93dHc8//zxycnJq/ToSiQQxMTFVjvv5+WHixIn6x7m5uXj77bfRrVs32NvbQ6FQYNiwYTh+/Li+TVJSkr7nZtKkSfphn6VLlwIwPgejuLgYb731Fnx8fCCXy9G5c2f8+9//xr2bVdflfayvrKws/POf/0T79u1hbW2N8PBw/Pjjj1XarVixAr169YKDgwMUCgW6deuGBQsW6M9rNBrExsYiKCgI1tbWcHFxwYMPPojExESzxUqtG3swiIzIycnBsGHD8PTTT2P8+PFo3749gNsTDO3t7fHmm2/C3t4ef/31F2bOnImCggJ8+umntV43Pj4ehYWFePnllyGRSDB//nyMHj0aly5dqvUv4127dmHNmjWYMmUKHBwc8J///AePP/440tPT4eLiAgA4evQoIiMj4eHhgdjYWGi1WsyaNQvt2rUz+bUnJCRAIpFgyJAhtbbVarXIzs6uctzGxgZ2dnZ49NFHYW9vj19//RUDBgwwaLNy5UqEhIQgNDQUAJCYmIhLly5h0qRJcHd3x6lTp/Dtt9/i1KlT2Ldvn1kmvl66dAlr167Fk08+CX9/f9y4cQOLFi3CgAEDcPr0aXh6eqJr166YNWsWZs6ciZdeegkPPfQQAOCBBx4wek1BEPDYY4/h77//xj//+U90794dCQkJeOedd3Dt2jV88cUXBu1NeR/rq7S0FAMHDkRKSgpeffVV+Pv7Y9WqVZg4cSLy8vIwbdo0ALdzPXbsWAwaNAiffPIJAODMmTPYvXu3vk1MTAzmzp2LF154AX369EFBQQEOHTqEI0eOICIiokFxUhshELVhU6dOFe79MRgwYIAAQPjmm2+qtC8pKaly7OWXXxZsbW0FtVqtP/bcc88Jvr6++sepqakCAMHFxUXIzc3VH1+3bp0AQFi/fr3+WHR0dJWYAAhWVlZCSkqK/tjx48cFAMLChQv1x6KiogRbW1vh2rVr+mMXLlwQLCwsqlyzOs8++6wwYMCAWttV5snYx8svv6xvN3bsWMHNzU2oqKjQH8vIyBCkUqkwa9Ys/TFjuf3ll18EAMKOHTv0x3744QcBgJCamqo/BkCIjo6u8nxfX1/hueee0z9Wq9WCVqs1aJOamirI5XKDWA4ePCgAEH744Ycq17z3vV27dq0AQPjoo48M2j3xxBOCRCIxeM9MfR+Nqfwe+vTTT6tt8+WXXwoAhOXLl+uPlZeXCyqVSrC3txcKCgoEQRCEadOmCQqFwuA9uVd4eLjw6KOP1hgTUU04REJkhFwux6RJk6oct7Gx0X9eWFiI7OxsPPTQQygpKcHZs2drve6YMWPg5OSkf1z51/GlS5dqfe7gwYMREBCgfxwWFgaFQqF/rlarxdatWzFy5Eh4enrq2wUGBmLYsGG1Xh8AdDodNm/ebPLwiJ+fHxITE6t8vP766/o2Y8aMQVZWlsGdOatXr4ZOp8OYMWP0x+7OrVqtRnZ2Nu6//34AwJEjR0yKpzZyuRxS6e3/9rRaLXJycmBvb4/OnTvX+2ts3LgRMpkMr732msHxt956C4IgYNOmTQbHa3sfG2Ljxo1wd3fH2LFj9ccsLS3x2muvoaioSD9U5ejoiOLi4hqHOxwdHXHq1ClcuHChwXFR28QCg8gILy8vWFlZVTl+6tQpjBo1CkqlEgqFAu3atdNPcszPz6/1uh06dDB4XFls3Lp1q87PrXx+5XOzsrJQWlqKwMDAKu2MHTPm4MGDuHnzpskFhp2dHQYPHlzl4+7bVCMjI6FUKrFy5Ur9sZUrV6J79+7o1KmT/lhubi6mTZuG9u3bw8bGBu3atYO/vz8A03JrCp1Ohy+++AJBQUGQy+VwdXVFu3btcOLEiXp/jcuXL8PT0xMODg4GxyvvRLp8+bLB8drex4a4fPkygoKC9EVUdbFMmTIFnTp1wrBhw+Dt7Y3nn3++yjyQWbNmIS8vD506dUK3bt3wzjvv4MSJEw2OkdoOFhhERtz913SlvLw8DBgwAMePH8esWbOwfv16JCYm6sewTbl1USaTGT0u3DMZ0NzPNdXGjRvh5+eH4OBgs11TLpdj5MiR+P3331FRUYFr165h9+7dBr0XAPDUU0/hu+++wyuvvII1a9Zgy5Yt+l969b0t9N7Jtx9//DHefPNN9O/fH8uXL0dCQgISExMREhLSZLeeNsX7WBs3NzccO3YMf/zxh37+yLBhw/Dcc8/p2/Tv3x8XL17E999/j9DQUCxevBg9e/bE4sWLmyxOatk4yZPIRElJScjJycGaNWvQv39//fHU1FQRo7rDzc0N1tbWSElJqXLO2DFjNmzYgOHDh5s7NIwZMwY//vgjtm3bhjNnzkAQBIMC49atW9i2bRtiY2Mxc+ZM/XFTu+ednJyQl5dncKy8vBwZGRkGx1avXo2HH34YS5YsMTiel5cHV1dX/eO6TCj19fXF1q1bUVhYaNCLUTlk5uvra/K1GsrX1xcnTpyATqcz6MUwFouVlRWioqIQFRUFnU6HKVOmYNGiRZgxY4a+x8vZ2RmTJk3CpEmTUFRUhP79+yMmJgYvvPBCk70marnYg0Fkosq/PO/+S7O8vBxff/21WCEZkMlkGDx4MNauXYvr16/rj6ekpFSZB2DMjRs3cOTIEbPcnnqvwYMHw9nZGStXrsTKlSvRp08f/fBHZexA1b/iv/zyS5OuHxAQgB07dhgc+/bbb6v0YMhksipfY9WqVbh27ZrBMTs7OwCoUrQYM3z4cGi1Wnz11VcGx7/44gtIJBKT57+Yw/Dhw5GZmWkwHFVRUYGFCxfC3t5efyfPvbf+SqVShIWFAQDKysqMtrG3t0dgYKD+PFFt2INBZKIHHngATk5OeO655/Daa69BIpFg2bJlTdq1XZuYmBhs2bIF/fr1w+TJk/W/+EJDQ2td9nrjxo2wtrbGww8/bPLXy8/Px/Lly42eu3sBLktLS4wePRorVqxAcXFxleWuFQoF+vfvj/nz50Oj0cDLywtbtmwxuXfohRdewCuvvILHH38cEREROH78OBISEgx6JQDgH//4B2bNmoVJkybhgQceQHJyMn7++Wd07NjRoF1AQAAcHR3xzTffwMHBAXZ2dujbt69BUVQpKioKDz/8MD744AOkpaUhPDwcW7Zswbp16/D6668bTOg0h23btkGtVlc5PnLkSLz00ktYtGgRJk6ciMOHD8PPzw+rV6/G7t278eWXX+p7WF544QXk5ubikUcegbe3Ny5fvoyFCxeie/fu+vkawcHBGDhwIHr16gVnZ2ccOnQIq1evxquvvmrW10OtmGj3rxA1A9XdphoSEmK0/e7du4X7779fsLGxETw9PYX/+7//ExISEgQAwt9//61vV91tqsZuMcQ9t1hWd5vq1KlTqzz33tswBUEQtm3bJvTo0UOwsrISAgIChMWLFwtvvfWWYG1tXU0WbnviiSeE4cOH19jmbjXdpmrsv5bExEQBgCCRSIQrV65UOX/16lVh1KhRgqOjo6BUKoUnn3xSuH79epX8GLtNVavVCu+++67g6uoq2NraCkOHDhVSUlKM3qb61ltvCR4eHoKNjY3Qr18/Ye/evcKAAQOq3Jq7bt06ITg4WH+Lb+Utq/e+t4IgCIWFhcIbb7wheHp6CpaWlkJQUJDw6aefCjqdzqBdXd7He1V+D1X3sWzZMkEQBOHGjRvCpEmTBFdXV8HKykro1q1bldttV69eLQwZMkRwc3MTrKyshA4dOggvv/yykJGRoW/z0UcfCX369BEcHR0FGxsboUuXLsKcOXOE8vLyGuMkqiQRhGb05xcRNYqRI0fWeMthRUUFXFxcMHfuXEyZMqWJoyOi1ohzMIhamdLSUoPHFy5cwMaNGzFw4MBqn5Obm4s33ngDo0aNauToiKitYA8GUSvj4eGh39Pj8uXLiIuLQ1lZGY4ePYqgoCCxwyOiNoKTPIlamcjISPzyyy/IzMyEXC6HSqXCxx9/zOKCiJoUezCIiIjI7DgHg4iIiMyOBQYRERGZXZubg6HT6XD9+nU4ODjUaTlgIiKitk4QBBQWFsLT07PKpnr3anMFxvXr1+Hj4yN2GERERC3WlStX4O3tXWObNldgVC6Ve+XKFSgUCgCARqPBli1bMGTIEFhaWooZXqvAfJofc2pezKf5Mafm1VzzWVBQAB8fH4ON/arT5gqMymERhUJhUGDY2tpCoVA0qzeypWI+zY85NS/m0/yYU/Nq7vk0ZYoBJ3kSERGR2bHAICIiIrNjgUFERERmJ+ocjLi4OMTFxSEtLQ0AEBISgpkzZ2LYsGFG22s0GsydOxc//vgjrl27hs6dO+OTTz5BZGRkE0ZNRER3EwQBFRUVsLCwgFqthlarFTukFk+j0YiWT0tLS8hksgZfR9QCw9vbG/PmzUNQUBAEQcCPP/6IESNG4OjRowgJCanS/sMPP8Ty5cvx3XffoUuXLkhISMCoUaOwZ88e9OjRQ4RXQETUtpWXlyMjIwPFxcVwd3fHlStXuMaQGQiCIFo+JRIJvL29YW9v36DriFpgREVFGTyeM2cO4uLisG/fPqMFxrJly/DBBx9g+PDhAIDJkydj69at+Oyzz7B8+fImiZmIiG7T6XRITU2FTCaDp6cnysvLYW9vX+sCTFQ7nU6HoqKiJs+nIAi4efMmrl69iqCgoAb1ZDSb21S1Wi1WrVqF4uJiqFQqo23KyspgbW1tcMzGxga7du2q9rplZWUoKyvTPy4oKABwu/tJo9HoP7/73zrFrRNw6PItZBWWwc1Bjt6+TpBJ61ZtmuMazUlD8knGMafmxXyaR1lZGbRaLby8vGBjY4PCwkLI5XL2YJiBIAgoLy8XJZ8uLi4oKipCaWkp5HK5wbm6/MyIvptqcnIyVCoV1Go17O3tER8fr++huNe4ceNw/PhxrF27FgEBAdi2bRtGjBgBrVZrUETcLSYmBrGxsVWOx8fHw9bWtkGxH8+RYE2aFHnld958RysBo/10CHcxLa3muAYRkRgsLCzg7u4OHx8fWFlZiR0OmUl5eTmuXLmCzMxMVFRUGJwrKSnBuHHjkJ+fr19LqjqiFxjl5eVIT09Hfn4+Vq9ejcWLF2P79u0IDg6u0vbmzZt48cUXsX79ekgkEgQEBGDw4MH4/vvvUVpaavT6xnowfHx8kJ2dbbDQVmJiIiIiIkxe0CTh1A38a8Vx3Ju8yjJh4dPhGBrSvtGv0RzVJ59UM+bUvJhP81Cr1bhy5Qr8/Pwgl8tRWFjIfZ7MpHLPDzHyqVarkZaWBh8fnyqjBgUFBXB1dTWpwBB9iMTKygqBgYEAgF69euHgwYNYsGABFi1aVKVtu3btsHbtWqjVauTk5MDT0xPvvfceOnbsWO315XJ5lS4e4PYs2Xv/YzF2zBitTsCcTeeqFAYAIOB2gTBn0zkMC/PSD3UIgoByrQ7qch3UFVoUqSsQ8+eZOl2jpTE1n2Q65tS8mM+G0Wq1kEgkkEql+l+ClY+pYXQ6HQBx8ln5flb3e9JUohcY99LpdNUOd1SytraGl5cXNBoNfvvtNzz11FNNFN1tB1JzkZGvrva8ACAjX42+c7ZCAKDWaFGq0UJXh76iymscSM2FKsCloSETETVrWp2AA6m5yCpUw83BGn38nVvcH1d+fn54/fXX8frrr4sdSrMgaoExffp0DBs2DB06dEBhYSHi4+ORlJSEhIQEAMCECRPg5eWFuXPnAgD279+Pa9euoXv37rh27RpiYmKg0+nwf//3f00ad1Zh9cXF3bKLy40el0oAS6kEZdraKw5TvxYRUUu1+WQGYtefNvjDzUNpjeioYESGepj969U25BAdHY2YmJg6X/fgwYOws7OrZ1S3DRw4EN27d8fnn3/eoOs0B6IWGFlZWZgwYQIyMjKgVCoRFhaGhIQEREREAADS09MNuobUajU+/PBDXLp0Cfb29hg+fDiWLVsGR0fHJo3bzcG69kYAZo8IwX3+zrCxlMHGUgb5//61lEmw71Iuxn63z2xfi4ioJdp8MgOTlx+pMlycma/G5OVHEDe+p9mLjIyMDP3nK1euxMyZM3Hu3Dn9sbvXfxAEAVqtFhYWtf+6bNeunVnjbOlEHShbsmQJ0tLSUFZWhqysLGzdulVfXABAUlISli5dqn88YMAAnD59Gmq1GtnZ2fjpp5/g6enZ5HH38XeGh9Ia1dXAEtyuvsf19UUXdwV8XezgprCG0sYSVha3x7Zquwb+d40+/s6N8AqIiBqHIAgoKa8w6aNQrUH0H6eqnYsGADF/nEahWmPS9Uy9Z8Hd3V3/oVQqIZFI9I/Pnj0LBwcHbNq0Cb169YJcLseuXbtw8eJFjBgxAu3bt4e9vT3uu+8+bN261eC6fn5++PLLL/WPJRIJFi9ejFGjRsHW1hZBQUH4448/6pfY//ntt98QEhICuVwOPz8/fPbZZwbnv/76awQFBcHa2hrt27fHE088oT+3evVqdOvWDTY2NnBxccHgwYNRXFzcoHhq0uzmYLQEMqkE0VHBmLz8CCSAwQ9HZcEQHRVc4/hhTdeo1KuFr4dBRG1PqUaL0JhEs1xLAJBZoEa3mC0mtT89ayhsrczza+29997Dv//9b3Ts2BFOTk64cuUKhg8fjjlz5kAul+Onn35CVFQUzp07hw4dOlR7ndjYWMyfPx+ffvopFi5ciGeeeQaXL1+Gs3Pd/3g8fPgwnnrqKcTExGDMmDHYs2cPpkyZAhcXF0ycOBGHDh3Ca6+9hmXLluGBBx5Abm4udu7cCeB2r83YsWMxf/58jBo1CoWFhdi5c6fJRVl9cKpvPUWGeiBufE+4Kw2HMNyV1iZ36VV3DUeb27N0NyRnYOeFm+YLmoiITDJr1ixEREQgICAAzs7OCA8Px8svv4zQ0FAEBQVh9uzZCAgIqLVHYuLEiRg7diwCAwPx8ccfo6ioCAcOHKhXTJ9//jkGDRqEGTNmoFOnTpg4cSJeffVVfPrppwBuTyuws7PDP/7xD/j6+qJHjx547bXXANwuMCoqKjB69Gj4+fmhW7dumDJlSoOXA68JezAaIDLUAxHB7g2a+VzdNT5cm4xfDlzB6yuOYcNrD1UpQoiImiMbSxlOzxpqUtsDqbmY+MPBWtstnXSfScPFNpYN36CrUu/evQ0eFxUVISYmBhs2bND/si4tLUV6enqN1wkLC9N/bmdnB4VCgaysrHrFdObMGYwYMcLgWL9+/fDll19Cq9UiIiICvr6+6NixIyIjIxEZGakfngkPD8egQYPQrVs3DB06FEOGDMETTzwBJyenesViCvZgNJBMKoEqwAUjuntBFeBSryENY9eIjgpBVw8FcorL8a9fjqBCq2uE6ImIzEsikcDWysKkj4eC2pk0n+2hoHYmXc+cC1LdezfI22+/jd9//x0ff/wxdu7ciWPHjqFbt24oLzd+t2Cle9eNkEgk+jUuzM3BwQFHjhzBL7/8Ag8PD8ycORPh4eHIy8uDTCZDYmIiNm3ahODgYCxcuBCdO3dGampqo8QCsMBotqwtZfj6mZ6wl1vgYNotfLrlXO1PIiJqQSrnogGoUmSYOp+tqezevRsTJ07EqFGj0K1bN7i7uyMtLa1JY+jatSt2795dJa5OnTrpNyWzsLDA4MGDMX/+fJw4cQJpaWn466+/ANwubvr164fY2FgcPXoUVlZW+P333xstXg6RNGP+rnaY/0QYpvx8BIu2X8J9vs4YHNzylg4nIqpO5Vy0e9fBcG/EdTDqIygoCGvWrEFUVBQkEglmzJjRaD0RN2/exLFjx1BcXAw7OztIpVJ4eHjgrbfewn333YfZs2djzJgx2Lt3L7766it8/fXXAIA///wTly5dQv/+/eHk5ISNGzdCp9Ohc+fO2L9/P7Zt24YhQ4bAzc0N+/fvx82bN9G1a9dGeQ0AC4xmb3g3D0x8wA9L96ThrVXH8ee/HoSPc8M2aSMiak7MMZ+tsX3++ed4/vnn8cADD8DV1RXvvvuufnduc4uPj0d8fLzBsdmzZ+PDDz/Er7/+ipkzZ2L27Nnw8PDArFmzMHHiRACAo6Mj1qxZg5iYGKjVagQFBeGXX35BSEgIzpw5gx07duDLL79EQUEBfH198dlnn2HYsGGN8hqAZrDZWVMrKCiAUqk02KhFo9Fg48aNGD58eLPcl6C8QocnF+3F8St5CPdW4tdXVJBbmG8yk7k193y2RMypeTGf5qFWq5Gamgp/f39YWVmhoKAACoWCe5GYgU6nEy2fd7+vxjY7u/d3aHX4XdACWFlI8d9xPaC0scTxq/mYu/Gs2CERERHViAVGC+HtZIvPnwoHACzdk4YNJzJqeQYREZF4WGC0IIO6tscrAwIAAO/+dgKXbhaJHBEREZFxLDBamLeHdEIfP2cUlVVgys9HoNZoxQ6JiIioChYYLYyFTIqF43rAxc4KZzMLEb3ulNghEVEb18buFWj1zPV+ssBogdorrLHg6R6QSICVh65g9eGrYodERG1Q5R04JSUlIkdC5lS5Omnl4l31xXUwWqgHg1zx+qBO+GLreXy4NhnBHgrkl2qa7T3kRNT6yGQyODo6IisrCzqdDjqdDmq1mrepmoFOp0N5eXmT51On0+HmzZuwtbWFhUXDSgQWGC3Yq48E4tDlXOy8kI2or3ZBq7vTreXRzFbBI6LWyd3dHcDt1SdLS0thY2Nj1j1B2ipBEETLp1QqRYcOHRr8dVlgtGAyqQRR4Z7YeSHboLgAgMx8NSYvP2Ly1vFERPUhkUjg4eEBJycnbNu2Df379+fiZWag0WiwY8cOUfJpZWVlll4TFhgtmFYn4IvE80bPCbi9WVDs+tOICHbncAkRNSqZTIaKigpYW1uzwDCD1pBPDpS1YAdScw02B7qXACAjX40DqblNFxQRERFYYLRoWYXVFxf1aUdERGQuLDBaMDcH69ob1aEdERGRubDAaMH6+DvDQ2mNmmZXtFfI0cffucliIiIiAlhgtGgyqQTRUcEAUG2RIbeQoZTLiRMRURNjgdHCRYZ6IG58T7grDYdB2jnIYS+3QHpuCV5edghlFSwyiIio6fA21VYgMtQDEcHuOJCaa7CS56nr+Rj77T7sTsnBmyuP4z9je/B2VSIiahLswWglZFIJVAEuGNHdC6oAF8ikEoR5O2LRs71hKZNgQ3IGYv44xU2JiIioSbDAaOUeDHLFF2O6QyIBlu27jAXbLogdEhERtQEsMNqAf4R5YtZjIQCAL7dewLJ9l0WOiIiIWjsWGG3Esyo/TBsUBACYue4kNpzIEDkiIiJqzVhgtCGvDw7C+Ps7QBCA11cexa4L2WKHRERErRQLjDZEIpEg9rFQPNrNAxqtgJeXHcKJq3lih0VERK0QC4w2RiaV4PMx4egX6ILici0m/nAQl24WiR0WERG1MqIWGHFxcQgLC4NCoYBCoYBKpcKmTZtqfM6XX36Jzp07w8bGBj4+PnjjjTegVnMzr7qQW8iw6Nne6OalRG5xOZ5dcgA3CphDIiIyH1ELDG9vb8ybNw+HDx/GoUOH8Mgjj2DEiBE4deqU0fbx8fF47733EB0djTNnzmDJkiVYuXIl3n///SaOvOWzl1vgh0n3wd/VDtfySjFhyQHkFpVj78UcrDt2DXsv5kCr45oZRERUP6Ku5BkVFWXweM6cOYiLi8O+ffsQEhJSpf2ePXvQr18/jBs3DgDg5+eHsWPHYv/+/U0Sb2vjai/HT8/3weNxe3DuRiH6zt0KjfZOUeGhtEZ0VDAiQz1EjJKIiFqiZrNUuFarxapVq1BcXAyVSmW0zQMPPIDly5fjwIED6NOnDy5duoSNGzfi2Wefrfa6ZWVlKCsr0z8uKCgAAGg0Gmg0Gv3nd//blrg7WOKFfr74ePN5g+ICADLz1Zi8/AgWPh2OoSHtTb5mW85nY2FOzYv5ND/m1Lyaaz7rEo9EEHnt6OTkZKhUKqjVatjb2yM+Ph7Dhw+vtv1//vMfvP322xAEARUVFXjllVcQFxdXbfuYmBjExsZWOR4fHw9bW1uzvIaWTCcAsUdkyCsHjO/JKsDRCojuqQW3MSEiattKSkowbtw45OfnQ6FQ1NhW9AKjvLwc6enpyM/Px+rVq7F48WJs374dwcHBVdomJSXh6aefxkcffYS+ffsiJSUF06ZNw4svvogZM2YYvb6xHgwfHx9kZ2frk6PRaJCYmIiIiAhYWlo2zgttpvan5mL894dqbbf8+d7o6+9s0jXbcj4bC3NqXsyn+TGn5tVc81lQUABXV1eTCgzRh0isrKwQGBgIAOjVqxcOHjyIBQsWYNGiRVXazpgxA88++yxeeOEFAEC3bt1QXFyMl156CR988AGk0qpzVuVyOeRyeZXjlpaWVd40Y8dau5ySCpPb1TU3bTGfjY05NS/m0/yYU/NqbvmsSyzNbh0MnU5n0ONwt5KSkipFhEwmAwDuElpPbg7WpjVkeomIqA5E7cGYPn06hg0bhg4dOqCwsBDx8fFISkpCQkICAGDChAnw8vLC3LlzAdy+6+Tzzz9Hjx499EMkM2bMQFRUlL7QoLrp4+8MD6U1MvPVNdYQ7605geJyLcb28YFEwskYRERUM1ELjKysLEyYMAEZGRlQKpUICwtDQkICIiIiAADp6ekGPRYffvghJBIJPvzwQ1y7dg3t2rVDVFQU5syZI9ZLaPFkUgmio4IxefkRSGDYUVH5OLCdPVJuFuH935Ox5XQmPnk8DO0VJvZ8EBFRmyRqgbFkyZIazyclJRk8trCwQHR0NKKjoxsxqrYnMtQDceN7Inb9aWTk31nR0/1/62BEBLvj+12p+HTLOSSdu4khX+zARyNDERXuKWLURETUnIk+yZOah8hQD0QEu+NAai6yCtVwc7BGH39nyP53b+qL/TtiQOd2ePPXYzh5rQD/+uUoEk5lYvaIUDjZWYkcPRERNTfNbpIniUcmlUAV4IIR3b2gCnDRFxeVOrV3wO9T+uG1QUGQSSX480QGhny5A3+fzdK30eoE7E/NxeFsCfan5nK5cSKiNoo9GFQnljIp3ozohEFd3PDmr8dw8WYxJi09iLF9fNDH3wXzN5/93zCLDD9dOMTlxomI2ij2YFC9hPs4YsNrD+H5fv4AgF8OXMEbK48ZzOEA7iw3vvlkhhhhEhGRSFhgUL1ZW8owMyoYy//Zp9plxCsHSGLXn+ZwCRFRG8ICgxpMJpWiptpBAJCRr8aB1Nwmi4mIiMTFAoMaLKtQXXujOrQjIqKWjwUGNZipy42bvCw5ERG1eCwwqMEqlxuvbgFxCQAP5e11NYiIqG1ggUENVrncOACjRYYAIDoquMq6GkRE1HqxwCCzqFxu3F1ZdRjE1d4KAzu7iRAVERGJhQUGmU1kqAd2vfsIlj/fGxOCtPhufA+4OVghu6gc3+64JHZ4RETUhFhgkFnJpBL09XdGL1cBAzu3wweP3h46+e/fKbiSWyJydERE1FRYYFCjeizcE339nVFWocNHG06LHQ4RETURFhjUqCQSCWaNCIVMKkHCqRvYfv6m2CEREVETYIFBja6zuwMmPuAHAIj54xTKKrTiBkRERI2OBQY1iWmDg+BqL0dqdjGW7EoVOxwiImpkLDCoSSisLfH+8C4AgIXbUnA9r1TkiIiIqDGxwKAmM6qHF+7zc0KpRos5G86IHQ4RETUiFhjUZCQSCWIfC4VUAmxIzsDulGyxQyIiokbCAoOaVLCnAs/e7wsAiP7jFMordCJHREREjYEFBjW5N4d0houdFVKyirB0Dyd8EhG1RiwwqMkpbSzx7rDbEz4XbL2AGwVqkSMiIiJzY4FBoniipze6+ziiuFyLjzdywicRUWvDAoNEIZVKMHtEKCQSYN2x69h3KUfskIiIyIxYYJBounkrMa5PBwBA9LpT0Gg54ZOIqLVggUGiemdoZzjZWuLcjUIs23tZ7HCIiMhMWGCQqBxtrfDO0NsTPr9IPI+sQk74JCJqDVhgkOjG3OeDMG8lCssqMG/TWbHDISIiM2CBQaKTSW9v6Q4Aa45cw/5LOdh7MQfrjl3D3os50OoEkSMkIqK6shA7ACIA6O7jiDG9fbDy0BU8s3g/Ku4qKjyU1oiOCkZkqIeIERIRUV2I2oMRFxeHsLAwKBQKKBQKqFQqbNq0qdr2AwcOhEQiqfLx6KOPNmHU1Fh6+zkBgEFxAQCZ+WpMXn4Em09miBEWERHVg6gFhre3N+bNm4fDhw/j0KFDeOSRRzBixAicOnXKaPs1a9YgIyND/3Hy5EnIZDI8+eSTTRw5mZtWJ+DzxPNGz1WWG7HrT3O4hIiohRB1iCQqKsrg8Zw5cxAXF4d9+/YhJCSkSntnZ2eDxytWrICtrS0LjFbgQGouMvKrv4NEAJCRr8aB1FyoAlyaLjAiIqqXZjMHQ6vVYtWqVSguLoZKpTLpOUuWLMHTTz8NOzu7atuUlZWhrKxM/7igoAAAoNFooNFo9J/f/S81TH3ymZFXbHI7jUZRr7haMn6PmhfzaX7MqXk113zWJR6JIAii9jknJydDpVJBrVbD3t4e8fHxGD58eK3PO3DgAPr27Yv9+/ejT58+1baLiYlBbGxslePx8fGwtbVtUOxkPhfyJfjqtKzWdq8GaxGk5DAJEZEYSkpKMG7cOOTn50OhqPmPPdELjPLycqSnpyM/Px+rV6/G4sWLsX37dgQHB9f4vJdffhl79+7FiRMnamxnrAfDx8cH2dnZ+uRoNBokJiYiIiIClpaWDX9RbVx98qnVCRj42Q7cKCiDsW9ICQB3pRx/v9kfMqnErPG2BPweNS/m0/yYU/NqrvksKCiAq6urSQWG6EMkVlZWCAwMBAD06tULBw8exIIFC7Bo0aJqn1NcXIwVK1Zg1qxZtV5fLpdDLpdXOW5paVnlTTN2jOqvLvm0BBDzWAgmLz8CCVClyBAAREeFwFpuZeYoWxZ+j5oX82l+zKl5Nbd81iWWZrfQlk6nM+hxMGbVqlUoKyvD+PHjmygqagqRoR6IG98T7krrKudkUsDLkUNaREQthag9GNOnT8ewYcPQoUMHFBYWIj4+HklJSUhISAAATJgwAV5eXpg7d67B85YsWYKRI0fCxYV3E7Q2kaEeiAh2x4HUXGQVquHmIMfS3WlIOH0Dr604ij//9SDs5KJ3vBERUS1E/Z86KysLEyZMQEZGBpRKJcLCwpCQkICIiAgAQHp6OqRSw06Wc+fOYdeuXdiyZYsYIVMTkEklBreidvVQ4MSCnUjNLkbs+lOY/0S4iNEREZEpRC0wlixZUuP5pKSkKsc6d+4MkeelUhNztLXCF2O6Y+x3+/Droavo36kd/hHmKXZYRERUg2Y3B4PImPs7uuDVh29PBp6+JhlXcktEjoiIiGrCAoNajGmDgtCzgyMK1RV4feUxVGh1YodERETVYIFBLYaFTIoFT/eAg9wChy/fwsK/UsQOiYiIqsECg1oUH2dbfDQqFACw8K8LOJCaK3JERERkDAsManFGdPfC4z29oROA11ccRX5J81qrn4iIWGBQCxU7IgR+Lra4nq/G9N9P8M4iIqJmhgUGtUj2cgsseLoHLKQSbEzOxK+HrogdEhER3YUFBrVY4T6OeHtoZwBAzB+nkZJVJHJERERUiQUGtWgvPdQRDwa6olSjxWu/HEVZhVbskIiICCwwqIWTSiX4/KlwONtZ4XRGAT7dfE7skIiICCwwqBVwU1hj/uNhAIDFu1KRdC5L5IiIiIgFBrUKg4Pb4zmVLwDg7VXHkZmvxt6LOVh37Br2XsyBVse7TIiImhL3vaZWY/rwrtifmouzmYXo/+nfKK+4s5S4h9Ia0VHBiAz1MPl6Wp1w17bx1ujj7wyZVNIYoRMRtTosMKjVsLaU4anePpj152mD4gIAMvPVmLz8COLG9zSpyNh8MgOx608jI1+tP1afIoWIqK3iEAm1GlqdgO92XjJ6rnKAJHb96VqHSzafzMDk5UcMigvgTpGy+WSGOcIlImrV2INBrcaB1NwqRcHdBAAZ+WoM+Xw7PJ1s4GhrBaWNBRxtrKC0sYTS1hIOcgt8sPYkjJUgAgAJbhcpEcHuHC4hIqoBCwxqNbIKqy8u7nYxuxgXs4vr9TUqi5QDqblQBbjU6xpERG0BCwxqNdwcrE1q9/aQTvBQ2iCvVIP8Ug3yS8qRX6pBXqkGqdnFuJxTUus1TC1miIjaKhYY1Gr08XeGh9Iamflqo0McEgDuSmtMHhhY7fDG3os5GPvdvlq/lqnFDBFRW8VJntRqyKQSREcFA7hdTNyt8nF0VHCNcycqi5SaZld4KG/fskpERNVjgUGtSmSoB+LG94S70rCHwV1pbdItqjUVKXe+RntO8CQiqgWHSKjViQz1QESwe70XyaosUu5dB8POSobici2W7U1H/05ueLizW2O9BCKiFo8FBrVKMqmkQXd5GCtSevs64Z3Vx7H22HVMWX4EP7/YFz07OJkxaiKi1oMFBlE1jBUp858IR26JBjvO38TzSw9i9SsqBLo5iBQhEVHzxTkYRHVgZSHFN+N7oruPI/JKNHh2yQFczysVOywiomaHBQZRHdlaWeCHifchoJ0dMvLVeHbJftwqLhc7LCKiZoUFBlE9ONlZ4ad/9oWH0hoXbxZj0tKDKCmvEDssIqJmgwUGUT15Odrgp+f7QGljiWNX8jB5+RFotLran0hE1AawwCBqgKD2Dvh+4n2wtpRi+/mbeGfVcehq2a2ViKgtYIFB1EC9fJ0Q90wvyKQSrD12HXM2noEgsMggoraNBQaRGTzcxQ2fPhEGAFiyKxXfbL8kckREROLiOhhEZjK6pzdyi8vx0YYz+GTzWbjYWeHxXt71XlGUiKglE7UHIy4uDmFhYVAoFFAoFFCpVNi0aVONz8nLy8PUqVPh4eEBuVyOTp06YePGjU0UMVHNXnioI14e0BEA8O5vJ9D7o0SM/W4fpq04hrHf7cODn/yFzSczRI6SiKjxiVpgeHt7Y968eTh8+DAOHTqERx55BCNGjMCpU6eMti8vL0dERATS0tKwevVqnDt3Dt999x28vLyaOHKi6r0X2QWqji4QANwq0Ricy8xXY/LyIywyiKjVE3WIJCoqyuDxnDlzEBcXh3379iEkJKRK+++//x65ubnYs2cPLC0tAQB+fn5NESqRyXQCkJpdbPScgNu7tMauP42IYHcOlxBRq9Vs5mBotVqsWrUKxcXFUKlURtv88ccfUKlUmDp1KtatW4d27dph3LhxePfddyGTyYw+p6ysDGVlZfrHBQUFAACNRgONRqP//O5/qWHaej73p+Yis0Bd7XkBQEa+GntTstDX39mka7b1nJob82l+zKl5Ndd81iUeiSDy/XTJyclQqVRQq9Wwt7dHfHw8hg8fbrRtly5dkJaWhmeeeQZTpkxBSkoKpkyZgtdeew3R0dFGnxMTE4PY2Ngqx+Pj42Fra2vW10IEAIezJfjpgvGC924TgrTo5crbWYmo5SgpKcG4ceOQn58PhUJRY1vRC4zy8nKkp6cjPz8fq1evxuLFi7F9+3YEBwdXadupUyeo1Wqkpqbqeyw+//xzfPrpp8jIMD6mbawHw8fHB9nZ2frkaDQaJCYmIiIiQj/0QvXX1vO5PzUX478/VGu75c/3rlMPRlvOqbkxn+bHnJpXc81nQUEBXF1dTSowRB8isbKyQmBgIACgV69eOHjwIBYsWIBFixZVaevh4QFLS0uD4ZCuXbsiMzMT5eXlsLKyqvIcuVwOuVxe5bilpWWVN83YMaq/tppPVaAbPJTWyMxXw1j1LgHgrrSGKtCtznMw2mpOGwvzaX7MqXk1t3zWJZZmt9CWTqcz6HG4W79+/ZCSkgKd7s5+D+fPn4eHh4fR4oJIDDKpBNFRt3vgjJUPAoDoqGBO8CSiVq1eBcaVK1dw9epV/eMDBw7g9ddfx7ffflun60yfPh07duxAWloakpOTMX36dCQlJeGZZ54BAEyYMAHTp0/Xt588eTJyc3Mxbdo0nD9/Hhs2bMDHH3+MqVOn1udlEDWayFAPxI3vCXeldZVz3X2UiAz1ECEqIqKmU68hknHjxuGll17Cs88+i8zMTERERCAkJAQ///wzMjMzMXPmTJOuk5WVhQkTJiAjIwNKpRJhYWFISEhAREQEACA9PR1S6Z0ayMfHBwkJCXjjjTcQFhYGLy8vTJs2De+++259XgZRo4oM9UBEsLt+Jc/yCh3e/e0Ejl3Jx56L2XggwFXsEImIGk29CoyTJ0+iT58+AIBff/0VoaGh2L17N7Zs2YJXXnnF5AJjyZIlNZ5PSkqqckylUmHfvn11jplIDDKpBKoAF/3jE1fzsWzfZXz05xms/9eDHCYholarXkMkGo1GP3Fy69ateOyxxwDcvo20urs5iAh4I6ITHKwtcDqjAL8dvlr7E4iIWqh6FRghISH45ptvsHPnTiQmJiIyMhIAcP36dbi4uNTybKK2y9nOCtMGBQEA5iecQ1FZhcgRERE1jnoVGJ988gkWLVqEgQMHYuzYsQgPDwdwe6XNyqETIjJugsoPfi62yC4qQ1xSitjhEBE1inrNwRg4cCCys7NRUFAAJycn/fGXXnqJq2MS1cLKQor3h3fFS8sO47udqXj6vg7wcebPDRG1LvXqwSgtLUVZWZm+uLh8+TK+/PJLnDt3Dm5ubmYNkKg1ighuD1VHF5RX6PDJ5rNih0NEZHb1KjBGjBiBn376CQCQl5eHvn374rPPPsPIkSMRFxdn1gCJWiOJRIIZ/wiGRAL8eSIDh9JyxQ6JiMis6lVgHDlyBA899BAAYPXq1Wjfvj0uX76Mn376Cf/5z3/MGiBRaxXsqcCY3j4AgNl/noZOx43PiKj1qFeBUVJSAgcHBwDAli1bMHr0aEilUtx///24fPmyWQMkas3eGtIZ9nILHL+aj7XHrokdDhGR2dSrwAgMDMTatWtx5coVJCQkYMiQIQBur8xZ2+5qRHRHOwc5pjwcAACYv/kcSsp52yoRtQ71KjBmzpyJt99+G35+fujTpw9UKhWA270ZPXr0MGuARK3d8/384e1kg8wCNRZtvyR2OEREZlGvAuOJJ55Aeno6Dh06hISEBP3xQYMG4YsvvjBbcERtgbWlDNOHdQUALNpxERn5pSJHRETUcPXert3d3R09evTA9evX9Tur9unTB126dDFbcERtxfBu7rjPzwlqjQ6fbj4ndjhERA1WrwJDp9Nh1qxZUCqV8PX1ha+vLxwdHTF79mzodDpzx0jU6lXetgoAa45ew7EreeIGRETUQPUqMD744AN89dVXmDdvHo4ePYqjR4/i448/xsKFCzFjxgxzx0jUJoR5O2J0Ty8At29bFQTetkpELVe9lgr/8ccfsXjxYv0uqgAQFhYGLy8vTJkyBXPmzDFbgERtyf8N7YJNyZk4fPkW/jyRgahwT7FDIiKql3r1YOTm5hqda9GlSxfk5nJFQqL6clda45UBt29bnbfpLNQarcgRERHVT70KjPDwcHz11VdVjn/11VcICwtrcFBEbdlL/TvCQ2mNa3mlWLIrVexwiIjqpV5DJPPnz8ejjz6KrVu36tfA2Lt3L65cuYKNGzeaNUCitsbGSoZ3I7vg9ZXH8PXfKRjdwwsXswpwOFsCl9RcqALdIJNKxA6TiKhG9erBGDBgAM6fP49Ro0YhLy8PeXl5GD16NE6dOoVly5aZO0aiNuexcE9093FEcbkWj3y2HeO/P4SfLsgw/vtDePCTv7D5ZIbYIRIR1ahePRgA4OnpWWUy5/Hjx7FkyRJ8++23DQ6MqC2TSiWICG6PY1fyUHrPPIzMfDUmLz+CuPE9ERnqYdL1tDoBB1JzkVWohpuDNfr4O7MXhIgaVb0LDCJqPFqdgOX7jG8cKACQAIhdfxoRwe61FgqbT2Ygdv1pZOSr9cc8lNaIjgo2uUAhIqqreq/kSUSN50BqrkFBcC8BQEa+GisOpONaXmm1d5tsPpmBycuPVLlWZS8Ih1qIqLGwB4OoGcoqrL64uNsHa0/qP7eXW8DF3goudlZwsZfD2c4SG05kwNhyXXXtBSEiqqs6FRijR4+u8XxeXl5DYiGi/3FzsDapnZOtJYrKKqDRCigqq0BRWQUu55SY9NzKXpADqblQBbg0IFoioqrqVGAolcpaz0+YMKFBARER0MffGR5Ka2Tmq432QEhwe1GuXe8+AqkEKFBXIKeoDDnF5cgpKkN2UTl2p2Rj08nMWr+Wqb0lRER1UacC44cffmisOIjoLjKpBNFRwZi8/AgkgEGRUTmYER0VrB/aUNpYQmljiY7t7rQLaGdvUoFham8JEVFdcJInUTMVGeqBuPE94a40LADcldYm3aJa2QtS0+wKJ1tL9PF3NkO0RESGOMmTqBmLDPVARLA79qZkYcvO/RjyUF+TV/KsqRek0q0SDRbtuIjJAwIgkXCiJxGZD3swiJo5mVSCvv7O6OUqoG8dF8iqrhfEQ2mNhzvfHk+Zv/kc3v3tBMordGaNm4jaNvZgELVylb0gxlby/HFPGmLXn8Kvh67iSm4pvhnfC0pbS7FDJqJWgD0YRG2ATCqBKsAFI7p7QRXgou8Fee4BPyx57j7YWcmw91IORsXtRlp2scjRElFrwAKDqI17uIsbVk9+AJ5Ka1y6WYxRX+/GwbRcscMiohZO1AIjLi4OYWFhUCgUUCgUUKlU2LRpU7Xtly5dColEYvBhbc1b7IgaqquHAmun9kO4txK3SjR45rv9+P3oVbHDIqIWTNQCw9vbG/PmzcPhw4dx6NAhPPLIIxgxYgROnTpV7XMUCgUyMjL0H5cvG98Qiojqxk1hjRUvqTAs1B3lWh3eWHkcnyeehyAI0OoE7L2Yg3XHrmHvxRxodcbuSSEiukPUSZ5RUVEGj+fMmYO4uDjs27cPISEhRp8jkUjg7u7eFOERtTk2VjL8d1xPzE84h2+2X8R/tl3AnpRsXL1VgsyCMn077sZKRLVpNneRaLVarFq1CsXFxVCpVNW2Kyoqgq+vL3Q6HXr27ImPP/642mIEAMrKylBWduc/xoKCAgCARqOBRqPRf373v9QwzKf5NXVO3xocgA5Ocny47jQOXb5V5XzlbqwLnw7H0JD2TRKTOfF71PyYU/NqrvmsSzwSQRBE7etMTk6GSqWCWq2Gvb094uPjMXz4cKNt9+7diwsXLiAsLAz5+fn497//jR07duDUqVPw9vY2+pyYmBjExsZWOR4fHw9bW1uzvhai1kQnAB8ekqG4AoDR9UAFOFoB0T214GasRG1DSUkJxo0bh/z8fCgUihrbil5glJeXIz09Hfn5+Vi9ejUWL16M7du3Izg4uNbnajQadO3aFWPHjsXs2bONtjHWg+Hj44Ps7Gx9cjQaDRITExEREQFLS64B0FDMp/mJkdP9qbkY//2hWtstf743+raw5cb5PWp+zKl5Ndd8FhQUwNXV1aQCQ/QhEisrKwQGBgIAevXqhYMHD2LBggVYtGhRrc+1tLREjx49kJKSUm0buVwOuVxu9Ln3vmnGjlH9MZ/m15Q5zSmpMLldS32f+T1qfsypeTW3fNYllma3DoZOpzPocaiJVqtFcnIyPDw40YzI3EzdZZW7sRKRMaL2YEyfPh3Dhg1Dhw4dUFhYiPj4eCQlJSEhIQEAMGHCBHh5eWHu3LkAgFmzZuH+++9HYGAg8vLy8Omnn+Ly5ct44YUXxHwZRK1S5W6smflqoxulAbfvJuFurERkjKgFRlZWFiZMmICMjAwolUqEhYUhISEBERERAID09HRIpXc6WW7duoUXX3wRmZmZcHJyQq9evbBnzx6T5msQUd2YshvrjEeD67T5GhG1HaIWGEuWLKnxfFJSksHjL774Al988UUjRkREd6vcjTV2/Wlk5Kv1xysLjowCdbXPJaK2TfRJnkTUvBnbjTXlZiFmrD2Ffyecw5Dg9vBx5i3fRGSo2U3yJKLm597dWJ/p44u+/s4o1WgxfU0yRL7bnYiaIRYYRFRnUqkE8x4Pg9xCil0p2Vh1mBujEZEhFhhEVC/+rnZ4M6ITAOCjP08jq5DzMYjoDhYYRFRv/3zQH928lChQVyB6XfW7IBNR28MCg4jqzUImxSePh8FCKsGmk5nYfDJD7JCIqJlggUFEDRLsqcArAwIAADPWnUJ+SfPa/ZGIxMECg4ga7NVHAtGxnR1uFpZhzsbTYodDRM0ACwwiajBrSxnmPx4GiQT49dBV7LqQLXZIRCQyFhhEZBa9/Zwx4X5fAMB7a06gpNy03ViJqHVigUFEZvNOZBd4Odrg6q1SfLblvNjhEJGIWGAQkdnYyy0wZ1QoAOD73ak4kn5L5IiISCwsMIjIrAZ2dsPoHl4QBOC9306gvEIndkhEJAIWGERkdjP+EQwXOyucv1GEr5NSxA6HiETAAoOIzM7Jzgoxj4UAAP77dwrOZRaKHBERNTUWGETUKP4R5oHBXdtDoxXw7m8noNVxx1WitsRC7ACIqHWSSCT4aGQo9l/KwbErefh+dypCPZXIKlTDzcEaffydIZNKxA6TiBoJCwwiajTuSmtMH94V7/+ejDkbzhic81BaIzoqGJGhHiJFR0SNiUMkRNSoHG0sjR7PzFdj8vIj3CCNqJVigUFEjUarEzB7g/G9SSpnZMSuP835GUStEAsMImo0B1JzkZGvrva8ACAjX40DqblNFxQRNQkWGETUaLIKqy8u6tOOiFoOFhhE1GjcHKzN2o6IWg4WGETUaPr4O8NDaY3qbkaV4PbdJH38nZsyLCJqAiwwiKjRyKQSREcFA4DRIkMAEB0VzPUwiFohFhhE1KgiQz0QN74n3JXGh0HacXiEqFXiQltE1OgiQz0QEeyOA6m5+pU8Vx26gjVHr2H6mhP4818PwcqCf+8QtSYsMIioScikEqgCXPSPu7g7YPv5mzh/owiLtl/EvwYFiRgdEZkb/2QgIlE42Vlh5v/mZyz8KwUXbxaJHBERmRMLDCISzWPhnujfqR3KtTpMX5MMHVf0JGo1WGAQkWgkEgnmjAyFjaUMB1Jz8euhK2KHRERmwgKDiETl42yLt4Z0AgB8vPEMV/UkaiVELTDi4uIQFhYGhUIBhUIBlUqFTZs2mfTcFStWQCKRYOTIkY0bJBE1uokP+KGblxIF6grE/mF8czQiallELTC8vb0xb948HD58GIcOHcIjjzyCESNG4NSpUzU+Ly0tDW+//TYeeuihJoqUiBqThUyKuaO7QSaVYENyBraeviF2SETUQKIWGFFRURg+fDiCgoLQqVMnzJkzB/b29ti3b1+1z9FqtXjmmWcQGxuLjh07NmG0RNSYQr2UeOFBfwDAjHUnUVRWIXJERNQQzWYdDK1Wi1WrVqG4uBgqlaradrNmzYKbmxv++c9/YufOnbVet6ysDGVlZfrHBQUFAACNRgONRqP//O5/qWGYT/NrKzmdOsAfG5MzcOVWKT7ZdAYzH+3SKF+nreSzKTGn5tVc81mXeCSCIIh6X1hycjJUKhXUajXs7e0RHx+P4cOHG227a9cuPP300zh27BhcXV0xceJE5OXlYe3atdVePyYmBrGxsVWOx8fHw9bW1lwvg4jM5GyeBHFnZJBAwOuhWvg5iB0REVUqKSnBuHHjkJ+fD4VCUWNb0QuM8vJypKenIz8/H6tXr8bixYuxfft2BAcHG7QrLCxEWFgYvv76awwbNgwATCowjPVg+Pj4IDs7W58cjUaDxMREREREwNLS0vwvso1hPs2vreX0ndXJWHs8A53c7PH75PvNvox4W8tnU2BOzau55rOgoACurq4mFRiiD5FYWVkhMDAQANCrVy8cPHgQCxYswKJFiwzaXbx4EWlpaYiKitIf0+l0AAALCwucO3cOAQEBVa4vl8shl8urHLe0tKzyphk7RvXHfJpfW8npzMdCsSMlB+ezirB03xVMfTiwUb5OW8lnU2JOzau55bMusTS7dTB0Op1Bj0OlLl26IDk5GceOHdN/PPbYY3j44Ydx7Ngx+Pj4iBAtETUGZzsrzPhHVwDAgm0XcInLiBO1OKL2YEyfPh3Dhg1Dhw4dUFhYiPj4eCQlJSEhIQEAMGHCBHh5eWHu3LmwtrZGaGiowfMdHR0BoMpxImr5Rnb3wu9Hr2PH+Zt4//dk/PLi/ZBIJGKHRUQmErUHIysrCxMmTEDnzp0xaNAgHDx4EAkJCYiIiAAApKenIyMjQ8wQiUgklcuIW1tKse8SlxEnamlE7cFYsmRJjeeTkpJqPL906VLzBUNEzY6Psy3ejOiEjzeexZwNZ/BwFze4OViLHRYRmaDZzcEgIrrb8/38Eeql+N8y4qew92IO1h27hr0Xc6Dl7qtEzZbod5EQEdXEQibFvNFheOyrXdiQnIkNyZn6cx5Ka0RHBSMy1EPECInIGPZgEFGzd/VWCYx1VmTmqzF5+RFsPsm5WkTNDQsMImrWtDoBseuN77BaWXPErj/N4RKiZoYFBhE1awdSc5GRr672vAAgI1+NA6m5TRcUEdWKBQYRNWtZhdUXF3ebu+kMfjmQjut5pTW20+oE7E/NxeFsCfan5rLng6iRcJInETVrpt6WeuJqPk5cTQYAdGpvj4Gd3TCgUzv09nOC3EIGANh8MgOx60//r0dEhp8uHOJEUaJGwgKDiJq1Pv7O8FBaIzNfDWN9DRIALvZWeKavL3ZcuInjV/Jw/kYRzt8owrc7LsHWSoYHAlzg6iDHigNVF+uqnCgaN74niwwiM2KBQUTNmkwqQXRUMCYvPwIJYFBkVC4c/tHIUESGeuCNiE64VVyOXSnZSDp3E9vP30R2URm2nsmq9vrC/64Tu/40IoLdIZNyOXIic+AcDCJq9iJDPRA3vifclYbDJe5K6yo9D052VogK98RnT4XjwPuD8Oe/HsSY+2reDJETRYnMjz0YRNQiRIZ6ICLYHQdSc5FVqIabgzX6+DvX2OMglUoQ6qXEAwEuWHmw9r1MTJ1QSkS1Y4FBRC2GTCqBKsClzs8zdaKom4O8ztcmIuM4REJErV7lRNHaZlcs23cZBWpNk8RE1NqxwCCiVq9yoiiAKkVG5WOpBNiYnIlH/7MTR9NvNWl8RK0RCwwiahNqmij6zfie+G3yA/B2ssGV3FI8+c1eLNp+ETouwkVUb5yDQURtRuVE0b0pWdiycz+GPNQXqkA3/UTRDa89hPfXJGNDcgbmbjqL3Rdz8NmT4WjHuRlEdcYeDCJqU2RSCfr6O6OXq4C+99yForSxxFfjemDu6G6QW0ix4/xNDFuwEzsv3BQxYqKWiQUGEdFdJBIJxvbpgPX/ehCd2tsju6gME74/gE82n4VGqwNwez+TvRdzsO7YNey9mMP9TIiM4BAJEZERndo7YN3UBzF7w2nE709HXNJF7LuUg8d7euO/f6cY7PBan/1MtDqhTmt6ELU0LDCIiKphYyXDx6O6oV+AK95bcwJH0/NwND2vSru67mdiuOnabdx0jVobDpEQEdXi0TAPrH/1QVjKjPcwVA6QxK4/XetwyeaTGZi8/IhBcQHcKVI2n8wwR8hEomMPBhGRCTLy1dBoqy8eKvczeTX+CII9FHC0tYTS1gqONpZwtLWEo40V7K0tEPPHaaO7wnLTNWptWGAQEZnA1H1KNp3MxKaTmfX6GndvulafJdGJmhMWGEREJjB1P5OocA/YWVkgr0SDvNJy5JVokF+qQV6JBqUarUnX4KZr1BqwwCAiMkHlfiaZ+WqjQxwS3F4V9MsxPaod3th+PgvPfX+w1q915noBIkPdIbeQNSxoIhFxkicRkQlM2c8kOiq4xrkTDwa2M2nTtW92XEK/eX9j4bYLyC0ur3fMRGJigUFEZKKa9jMx5RbV2ooUCYBRPbzgrrBGdlEZPks8D9XcbXj/92SkZBVVuR4X/KLmjEMkRER1ULmfSX0XyaosUu5dB8P9rnUwNFodNiZn4Ludl3DyWgHi96cjfn86Hunihhce9IcqwAUJpzK5lgY1aywwiIjqSCaVNOguj9qKFEuZFCO6e+GxcE8cSM3F4l2p2HrmBv46m4W/zmbBy9EG1/JKq1y3rgt+ETUmFhhERCIwpUiRSCTo29EFfTu6IDW7GD/sTsWvB68YLS4ArqVBzQvnYBARtQD+rnaYNSIUC8f1qLHd3WtpEIlJ1AIjLi4OYWFhUCgUUCgUUKlU2LRpU7Xt16xZg969e8PR0RF2dnbo3r07li1b1oQRExGJq6TctLU0Np/MQEl5RSNHQ1Q9UYdIvL29MW/ePAQFBUEQBPz4448YMWIEjh49ipCQkCrtnZ2d8cEHH6BLly6wsrLCn3/+iUmTJsHNzQ1Dhw4V4RUQETUtUxf8+nHvZfx66CoGB7dHVJgHBnRuZ3RdDe7qSo1F1AIjKirK4PGcOXMQFxeHffv2GS0wBg4caPB42rRp+PHHH7Fr1y4WGETUJtS24BcA2MtlcLK1wpVbpVh//DrWH78OB2sLDA1xR1S4Jx4IcIGlTMpdXalRNZtJnlqtFqtWrUJxcTFUKlWt7QVBwF9//YVz587hk08+qbZdWVkZysrK9I8LCgoAABqNBhqNRv/53f9SwzCf5secmldLz+cHwzrjXyuOQwIYFBmV/Q7zRoViSLAbkq8VYENyJjaczMSNgjKsPnwVqw9fhZOtJUI8FNh1MafKtSvvRFn4dDiGhrQ3OaaWntPmprnmsy7xSARBEHVlluTkZKhUKqjVatjb2yM+Ph7Dhw+vtn1+fj68vLxQVlYGmUyGr7/+Gs8//3y17WNiYhAbG1vleHx8PGxtbc3yGoiImtrxHAnWpEmRV35nOMPRSsBoPx3CXQz/W9cJQGohcDhbimM5EhRX1DYEIsDRCojuqYUpoyU6AbhYIEGBBlBYAgEKwaTnUctTUlKCcePGIT8/HwqFosa2ohcY5eXlSE9PR35+PlavXo3Fixdj+/btCA4ONtpep9Ph0qVLKCoqwrZt2zB79mysXbu2yvBJJWM9GD4+PsjOztYnR6PRIDExEREREbC0tDT7a2xrmE/zY07Nq7XkU6sTcOjyLWQVlsHNQY7evk61zp+o0Orww97LmJ9wodbrzxkRjNE9PGEhq/5+gIRTN/DRxrPILLjz/6y7Qo4Ph3epUw8IGWqu36MFBQVwdXU1qcAQfYjEysoKgYGBAIBevXrh4MGDWLBgARYtWmS0vVQq1bfv3r07zpw5g7lz51ZbYMjlcsjl8irHLS0tq7xpxo5R/TGf5secmldLz6clgAc71e2XuKUl4OVkZ1LbD9adxpxN5xDmrUR3Hyf06OCIHj6OcFPcnmi6+WQG/rXieJW5IDcKyvCvFce54JcZNLfv0brEInqBcS+dTmfQ42Du9kREbZ2pd6JYW0pRUq7Fvku52HfpzroaXo42CPdRYueFbKMTTcVa8It3xDQvohYY06dPx7Bhw9ChQwcUFhYiPj4eSUlJSEhIAABMmDABXl5emDt3LgBg7ty56N27NwICAlBWVoaNGzdi2bJliIuLE/NlEBG1KKZuPb/9nYeRllOMo+m3cDQ9D8eu5OHcjUJcyyutdjXRSncv+NWQZdVNxTtimh9RC4ysrCxMmDABGRkZUCqVCAsLQ0JCAiIiIgAA6enpkErvjP0VFxdjypQpuHr1KmxsbNClSxcsX74cY8aMEeslEBG1OJW7uk5efqTaO1Gio4JhZSFFp/YO6NTeAWPu6wAAKFRrkHw1H/EH0vHniYxav1ZWobrWNg21+WQGJi8/UqVY4t4s4hK1wFiyZEmN55OSkgwef/TRR/joo48aMSIiorbBlF1djXGwtsQDga6QSCQmFRhyi8ZdMFqrExC7/nSzGqqh25rdHAwiImoaDdl63pQFvwBg2oqjGNsnFy8P6AgPpY35gv+fA6m5BgXSvZp6qIbuYIFBRNSG1Xfr+dqGWQQAvi62uJxTgqV70vDz/st4vKc3XhkQAD/Xqnex1HWCplYn4Ej6LSzedcmkeJtiqIYMscAgIqJ6qW2YZWiIO3alZOOrv1KwPzUXKw5ewa+HriAq3BNTBgais7sDANMnaBaqNdhxPhvbztzA3+eycKvE9FUlTb1zhsyHBQYREdVb5TDL3pQsbNm5H0Me6gtVoJu+9+GhoHZ4KKgdDqXl4qu/U5B07ibWHbuOdceuY0hwe/T0dcInm85WO0Fz9shQVGh12HY2C/su5UCjvdNSYW2BAZ3aYeeFbOSXamocqvntyBX4utjC09H8wzRkHAsMIiJqEJlUgr7+zsg5I6BvNUMbvf2csXRSH5y8lo///p2CzacyseX0DWw5fcPoNSuLhQ/XnjQ47u9qh0Fd3DCoa3v09nPSb9pmbKjmbqsPX8MfxzMw8QE/TBkYAEdbq/q/YDIJCwwiImoyoV5KxI3vhZSsQsT+cRo7U7JrfU4XdweM7umFQV3bI6CdfZXz1Q3VVA6zuCms8cmms9ifmotvd1zCLwfSMXlgACY94A8bqztb2HOhLvNigUFERE0u0M0BT/T2NqnAmDwwACO6e9XYprY7Yla8dD+Szt/EJ5vO4mxmIeZvPocf96Rh2qBOeKq3N7aeucGFusyMBQYREYnC1ImXprar6Y4YiUSChzu7YUBQO6w7fg2fbTmPq7dK8f7vyViw9TxuFFbdcoILdTVM466AQkREVI3KtTSqG4SQ4HYvQh9/Z7N9TalUglE9vLHtrQGIjgqGk62l0eICuDOfI3b9aWh1om483iKxwCAiIlFUrqUBoEqRcfeS5Y0xD0JuIcOkfv747MnwGtvdvVAX1Q0LDCIiEk3lBE13peEwiLvSukmGJgrLKkxqd+VWSaPG0RpxDgYREYmqIUuWN5Sp8zveX5OMLacyMSzUA4O7tofS1tJoO96JcgcLDCIiEl19lyxvKFP2VJFJJajQCdh6Jgtbz2TBQipBv0BXDAt1x5AQdzjb3V5Tg1vGG2KBQUREbZYpW9d/NbYHOrazx8bkDGw+mYlzNwqx/fxNbD9/Ex+sPYm+/s7o4GKLFQeuVLm+WHeiNIeeFBYYRETUppm6dX1ndwe8EdEJF28WYfPJTGxMzsCp6wXYczEHey7mGL22GFvGN5eeFBYYRETU5tVlHkhAO3tMfTgQUx8ORHpOCb7ZnoJ4I70XlZpyy/jKZdOr29ulKXtSeBcJERER7swDGdHdC6oAF5N6Gzq42KJvR9OKho83nsbP+y/jWl5pje20OgH7U3NxOFuC/am5Jq/BodUJiF1/2uhcEjHW9GAPBhERUQOYeidK8rUCJP9+e/O2QDd7DOzUDgM6t0Mff2fILW7viWI4vCHDTxcOmTy8sfPCTYNhkXs1ZU8KwAKDiIioQWq7E0UCwMXeChNUvth5IRtH0vOQklWElKwiLN6VChtLGVQBLnBzkGPFwZoniqo6uuJybjHSckqQnnP738s5xbicU4KsalYkvVdWYfVFiDmxwCAiImoAU+5E+WhkKCJDPfDaoE7IL9Fg98VsJJ3LwvbzN3GjoAx/nc2q9vqV15v88xEIZhjdMLXHpaFYYBARETWQqXeiAIDS1hLDu3lgeDcPCIKAs5mF+GlvGn6pYaIoAH1x0c5BDj8XW/i62MHX2Ra+rnbwc7GFt6MtHl24s8aeFHcz7+1SExYYREREZlCfFUklEgm6eihwf0eXWgsMAJj/RBie6u1T7fnaelIaa28XY1hgEBERmUl9VyQ1ddjCx8m2xvN16UlpbCwwiIiIRGbKRFFThzfE3NvlbiwwiIiIRGbKRNG6DG+ItbfL3bjQFhERUTMg9tb15sYeDCIiomaicnhjb0oWtuzcjyEP9YUq0K1FbvnOAoOIiKgZkUkl6OvvjJwzAvqKMHfCXDhEQkRERGbHAoOIiIjMjgUGERERmR0LDCIiIjI7FhhERERkdiwwiIiIyOza3G2qwv+2oysoKNAf02g0KCkpQUFBASwtLcUKrdVgPs2POTUv5tP8mFPzaq75rPzdKZiwb3ybKzAKCwsBAD4+1e9GR0RERNUrLCyEUqmssY1EMKUMaUV0Oh2uX78OBwcHSCS3Fy8pKCiAj48Prly5AoVCIXKELR/zaX7MqXkxn+bHnJpXc82nIAgoLCyEp6cnpNKaZ1m0uR4MqVQKb29vo+cUCkWzeiNbOubT/JhT82I+zY85Na/mmM/aei4qcZInERERmR0LDCIiIjI7FhgA5HI5oqOjIZfLxQ6lVWA+zY85NS/m0/yYU/NqDflsc5M8iYiIqPGxB4OIiIjMjgUGERERmR0LDCIiIjI7FhhERERkdm2+wPjvf/8LPz8/WFtbo2/fvjhw4IDYIbUIMTExkEgkBh9dunTRn1er1Zg6dSpcXFxgb2+Pxx9/HDdu3BAx4uZnx44diIqKgqenJyQSCdauXWtwXhAEzJw5Ex4eHrCxscHgwYNx4cIFgza5ubl45plnoFAo4OjoiH/+858oKipqwlfRvNSW04kTJ1b5vo2MjDRow5zeMXfuXNx3331wcHCAm5sbRo4ciXPnzhm0MeVnPT09HY8++ihsbW3h5uaGd955BxUVFU35UpoFU/I5cODAKt+jr7zyikGblpLPNl1grFy5Em+++Saio6Nx5MgRhIeHY+jQocjKyhI7tBYhJCQEGRkZ+o9du3bpz73xxhtYv349Vq1ahe3bt+P69esYPXq0iNE2P8XFxQgPD8d///tfo+fnz5+P//znP/jmm2+wf/9+2NnZYejQoVCr1fo2zzzzDE6dOoXExET8+eef2LFjB1566aWmegnNTm05BYDIyEiD79tffvnF4Dxzesf27dsxdepU7Nu3D4mJidBoNBgyZAiKi4v1bWr7WddqtXj00UdRXl6OPXv24Mcff8TSpUsxc+ZMMV6SqEzJJwC8+OKLBt+j8+fP159rUfkU2rA+ffoIU6dO1T/WarWCp6enMHfuXBGjahmio6OF8PBwo+fy8vIES0tLYdWqVfpjZ86cEQAIe/fubaIIWxYAwu+//65/rNPpBHd3d+HTTz/VH8vLyxPkcrnwyy+/CIIgCKdPnxYACAcPHtS32bRpkyCRSIRr1641WezN1b05FQRBeO6554QRI0ZU+xzmtGZZWVkCAGH79u2CIJj2s75x40ZBKpUKmZmZ+jZxcXGCQqEQysrKmvYFNDP35lMQBGHAgAHCtGnTqn1OS8pnm+3BKC8vx+HDhzF48GD9MalUisGDB2Pv3r0iRtZyXLhwAZ6enujYsSOeeeYZpKenAwAOHz4MjUZjkNsuXbqgQ4cOzK2JUlNTkZmZaZBDpVKJvn376nO4d+9eODo6onfv3vo2gwcPhlQqxf79+5s85pYiKSkJbm5u6Ny5MyZPnoycnBz9Oea0Zvn5+QAAZ2dnAKb9rO/duxfdunVD+/bt9W2GDh2KgoICnDp1qgmjb37uzWeln3/+Ga6urggNDcX06dNRUlKiP9eS8tnmNjurlJ2dDa1Wa/AmAUD79u1x9uxZkaJqOfr27YulS5eic+fOyMjIQGxsLB566CGcPHkSmZmZsLKygqOjo8Fz2rdvj8zMTHECbmEq82Ts+7PyXGZmJtzc3AzOW1hYwNnZmXmuRmRkJEaPHg1/f39cvHgR77//PoYNG4a9e/dCJpMxpzXQ6XR4/fXX0a9fP4SGhgKAST/rmZmZRr+PK8+1VcbyCQDjxo2Dr68vPD09ceLECbz77rs4d+4c1qxZA6Bl5bPNFhjUMMOGDdN/HhYWhr59+8LX1xe//vorbGxsRIyMqHpPP/20/vNu3bohLCwMAQEBSEpKwqBBg0SMrPmbOnUqTp48aTDXiuqvunzePd+nW7du8PDwwKBBg3Dx4kUEBAQ0dZgN0maHSFxdXSGTyarMdr5x4wbc3d1FiqrlcnR0RKdOnZCSkgJ3d3eUl5cjLy/PoA1za7rKPNX0/enu7l5lQnJFRQVyc3OZZxN17NgRrq6uSElJAcCcVufVV1/Fn3/+ib///hve3t7646b8rLu7uxv9Pq481xZVl09j+vbtCwAG36MtJZ9ttsCwsrJCr169sG3bNv0xnU6Hbdu2QaVSiRhZy1RUVISLFy/Cw8MDvXr1gqWlpUFuz507h/T0dObWRP7+/nB3dzfIYUFBAfbv36/PoUqlQl5eHg4fPqxv89dff0Gn0+n/U6KaXb16FTk5OfDw8ADAnN5LEAS8+uqr+P333/HXX3/B39/f4LwpP+sqlQrJyckGhVtiYiIUCgWCg4Ob5oU0E7Xl05hjx44BgMH3aIvJp9izTMW0YsUKQS6XC0uXLhVOnz4tvPTSS4Kjo6PB7Fwy7q233hKSkpKE1NRUYffu3cLgwYMFV1dXISsrSxAEQXjllVeEDh06CH/99Zdw6NAhQaVSCSqVSuSom5fCwkLh6NGjwtGjRwUAwueffy4cPXpUuHz5siAIgjBv3jzB0dFRWLdunXDixAlhxIgRgr+/v1BaWqq/RmRkpNCjRw9h//79wq5du4SgoCBh7NixYr0k0dWU08LCQuHtt98W9u7dK6Smpgpbt24VevbsKQQFBQlqtVp/Deb0jsmTJwtKpVJISkoSMjIy9B8lJSX6NrX9rFdUVAihoaHCkCFDhGPHjgmbN28W2rVrJ0yfPl2MlySq2vKZkpIizJo1Szh06JCQmpoqrFu3TujYsaPQv39//TVaUj7bdIEhCIKwcOFCoUOHDoKVlZXQp08fYd++fWKH1CKMGTNG8PDwEKysrAQvLy9hzJgxQkpKiv58aWmpMGXKFMHJyUmwtbUVRo0aJWRkZIgYcfPz999/CwCqfDz33HOCINy+VXXGjBlC+/btBblcLgwaNEg4d+6cwTVycnKEsWPHCvb29oJCoRAmTZokFBYWivBqmoeaclpSUiIMGTJEaNeunWBpaSn4+voKL774YpU/KJjTO4zlEoDwww8/6NuY8rOelpYmDBs2TLCxsRFcXV2Ft956S9BoNE38asRXWz7T09OF/v37C87OzoJcLhcCAwOFd955R8jPzze4TkvJJ7drJyIiIrNrs3MwiIiIqPGwwCAiIiKzY4FBREREZscCg4iIiMyOBQYRERGZHQsMIiIiMjsWGERERGR2LDCIiIjI7FhgEBERkdmxwCCiRnPz5k1MnjwZHTp0gFwuh7u7O4YOHYrdu3cDACQSCdauXStukETUKCzEDoCIWq/HH38c5eXl+PHHH9GxY0fcuHED27ZtQ05OjtihEVEj414kRNQo8vLy4OTkhKSkJAwYMKDKeT8/P1y+fFn/2NfXF2lpaQCAdevWITY2FqdPn4anpyeee+45fPDBB7CwuP03kUQiwddff40//vgDSUlJ8PDwwPz58/HEE080yWsjotpxiISIGoW9vT3s7e2xdu1alJWVVTl/8OBBAMAPP/yAjIwM/eOdO3diwoQJmDZtGk6fPo1FixZh6dKlmDNnjsHzZ8yYgccffxzHjx/HM888g6effhpnzpxp/BdGRCZhDwYRNZrffvsNL774IkpLS9GzZ08MGDAATz/9NMLCwgDc7on4/fffMXLkSP1zBg8ejEGDBmH69On6Y8uXL8f//d//4fr16/rnvfLKK4iLi9O3uf/++9GzZ098/fXXTfPiiKhG7MEgokbz+OOP4/r16/jjjz8QGRmJpKQk9OzZE0uXLq32OcePH8esWbP0PSD29vZ48cUXkZGRgZKSEn07lUpl8DyVSsUeDKJmhJM8iahRWVtbIyIiAhEREZgxYwZeeOEFREdHY+LEiUbbFxUVITY2FqNHjzZ6LSJqGdiDQURNKjg4GMXFxQAAS0tLaLVag/M9e/bEuXPnEBgYWOVDKr3zX9a+ffsMnrdv3z507dq18V8AEZmEPRhE1ChycnLw5JNP4vnnn0dYWBgcHBxw6NAhzJ8/HyNGjABw+06Sbdu2oV+/fpDL5XBycsLMmTPxj3/8Ax06dMATTzwBqVSK48eP4+TJk/joo4/011+1ahV69+6NBx98ED///DMOHDiAJUuWiPVyiegenORJRI2irKwMMTEx2LJlCy5evAiNRgMfHx88+eSTeP/992FjY4P169fjzTffRFpaGry8vPS3qSYkJGDWrFk4evQoLC0t0aVLF7zwwgt48cUXAdye5Pnf//4Xa9euxY4dO+Dh4YFPPvkETz31lIivmIjuxgKDiFocY3efEFHzwjkYREREZHYsMIiIiMjsOMmTiFocjuwSNX/swSAiIiKzY4FBREREZscCg4iIiMyOBQYRERGZHQsMIiIiMjsWGERERGR2LDCIiIjI7FhgEBERkdn9P3NwdGTj9qBbAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# ‡πÅ‡∏õ‡∏•‡∏á log_history ‡πÄ‡∏õ‡πá‡∏ô DataFrame ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏á‡πà‡∏≤‡∏¢\n",
    "df = pd.DataFrame(trainer.state.log_history)\n",
    "\n",
    "# ===== ‡∏Å‡∏£‡∏≤‡∏ü Loss =====\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(df[\"step\"], df[\"loss\"], label=\"Train Loss\", marker=\"o\")\n",
    "if \"eval_loss\" in df.columns:\n",
    "    plt.plot(df[\"step\"], df[\"eval_loss\"], label=\"Eval Loss\", marker=\"x\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training / Evaluation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ===== ‡∏Å‡∏£‡∏≤‡∏ü Accuracy =====\n",
    "if \"eval_accuracy\" in df.columns or \"accuracy\" in df.columns:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    acc_col = \"eval_accuracy\" if \"eval_accuracy\" in df.columns else \"accuracy\"\n",
    "    plt.plot(df[\"step\"], df[acc_col], label=\"Eval Accuracy\", color=\"green\", marker=\"x\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Evaluation Accuracy over Steps\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a76ec468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved to: lora_model_20251015_194820\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "save_dir = f\"lora_model_{timestamp}\"\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "print(f\"‚úÖ Model saved to: {save_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
